{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what does TensorFlow offer? Here’s a summary:\n",
    "\n",
    " - Its core is very similar to NumPy, but with GPU support.\n",
    "\n",
    " - It supports distributed computing (across multiple devices and servers).\n",
    "\n",
    " - It includes a kind of just-in-time (JIT) compiler that allows it to optimize computations for speed and memory usage. It works by extracting the computation graph from a Python function, then optimizing it (e.g., by pruning unused nodes), and finally running it efficiently (e.g., by automatically running independent operations in parallel).\n",
    "\n",
    " - Computation graphs can be exported to a portable format, so you can train a TensorFlow model in one environment (e.g., using Python on Linux) and run it in another (e.g., using Java on an Android device).\n",
    "\n",
    " - It implements autodiff (see Chapter 10 and Appendix D of the hands-on book) and provides some excellent optimizers, such as RMSProp and Nadam (see Chapter 11), so you can easily minimize all sorts of loss functions.\n",
    " \n",
    "Below is a summary of brief description of the different components of `tensorflow`. Note that `tf.estimators` are just another Deep Learning API, but the TensorFlow team recommends"
   ]
  },
  {
   "attachments": {
    "mls2_1201.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![mls2_1201.png](attachment:mls2_1201.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the lowest level, each TensorFlow operation (op for short) is implemented using highly efficient C++ code.2 Many operations have multiple implementations called kernels: each kernel is dedicated to a specific device type, such as CPUs, GPUs, or even TPUs (tensor processing units). As you may know, GPUs can dramatically speed up computations by splitting them into many smaller chunks and running them in parallel across many GPU threads. TPUs are even faster: they are custom ASIC chips built specifically for Deep Learning operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures. We also check that Python 3.5 or later is installed (although Python 2.x may work, it is deprecated so we strongly recommend you use Python 3 instead), as well as Scikit-Learn ≥0.20 and TensorFlow ≥2.0-preview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# TensorFlow ≥2.0-preview is required\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"deep\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors and operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=0, shape=(2, 3), dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant([[1., 2., 3.], [4., 5., 6.]]) # matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=2, shape=(), dtype=int32, numpy=42>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(42) # scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=4, shape=(2, 3), dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tf.constant([[1., 2., 3.], [4., 5., 6.]])\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=9, shape=(2, 2), dtype=float32, numpy=\n",
       "array([[2., 3.],\n",
       "       [5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=14, shape=(2, 1), dtype=float32, numpy=\n",
       "array([[2.],\n",
       "       [5.]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tf.newaxis seem to serve as the same purpose as np.newaxis - to increase the dimension. \n",
    "#Note that without tf.newaxis, the result should have been of shape (2,)\n",
    "t[..., 1, tf.newaxis] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that writing `t + 10` is equivalent to calling `tf.add(t, 10)` (indeed, Python calls the magic method `t.__add__(10)`, which just calls `tf.add(t, 10))`. Other operators like `-` and `*` are also supported. The `@` operator was added in Python 3.5, for matrix multiplication: it is equivalent to calling the `tf.matmul()` function.\n",
    "\n",
    "You will find all the basic math operations you need (`tf.add()`, `tf.multiply()`, `tf.square()`, `tf.exp()`, `tf.sqrt()`, etc.) and most operations that you can find in NumPy (e.g., `tf.reshape()`, `tf.squeeze()`, `tf.tile()`). Some functions have a different name than in NumPy; for instance, tf.reduce_mean(), tf.reduce_sum(), tf.reduce_max(), and tf.math.log() are the equivalent of `np.mean()`, `np.sum()`, `np.max()` and `np.log()`. When the name differs, there is often a good reason for it. For example, in TensorFlow you must write tf.transpose(t); you cannot just write `t.T` like in NumPy. The reason is that the `tf.transpose()` function does not do exactly the same thing as NumPy’s T attribute: in TensorFlow, a new tensor is created with its own copy of the transposed data, while in NumPy, `t.T` is just a transposed view on the same data. Similarly, the `tf.reduce_sum()` operation is named this way because its GPU kernel (i.e., GPU implementation) uses a reduce algorithm that does not guarantee the order in which the elements are added: because 32-bit floats have limited precision, the result may change ever so slightly every time you call this operation. The same is true of `tf.reduce_mean()` (but of course `tf.reduce_max()` is deterministic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=17, shape=(2, 3), dtype=float32, numpy=\n",
       "array([[11., 12., 13.],\n",
       "       [14., 15., 16.]], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=19, shape=(2, 3), dtype=float32, numpy=\n",
       "array([[ 1.,  4.,  9.],\n",
       "       [16., 25., 36.]], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.square(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=23, shape=(2, 2), dtype=float32, numpy=\n",
       "array([[14., 32.],\n",
       "       [32., 77.]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t @ tf.transpose(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `keras.backend`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Keras API has its own low-level API, located in `keras.backend`. It includes functions like `square()`, `exp()`, and `sqrt()`. In `tf.keras`, these functions generally just call the corresponding TensorFlow operations. If you want to write code that will be portable to other Keras implementations, you should use these Keras functions. However, they only cover a subset of all functions available in TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=29, shape=(3, 2), dtype=float32, numpy=\n",
       "array([[11., 26.],\n",
       "       [14., 35.],\n",
       "       [19., 46.]], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "K = keras.backend\n",
    "K.square(K.transpose(t)) + 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From/To NumPy\n",
    "\n",
    "Notice that NumPy uses 64-bit precision by default, while TensorFlow uses 32-bit. This is because 32-bit precision is generally more than enough for neural networks, plus it runs faster and uses less RAM. So when you create a tensor from a NumPy array, make sure to set `dtype=tf.float32`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=31, shape=(3,), dtype=float64, numpy=array([2., 4., 5.])>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([2., 4., 5.])\n",
    "tf.constant(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=36, shape=(3,), dtype=float64, numpy=array([ 4., 16., 25.])>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.square(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  4.,  9.],\n",
       "       [16., 25., 36.]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.square(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conflicting Types\n",
    "\n",
    "Type conversions can significantly hurt performance, and they can easily go unnoticed when they are done automatically. To avoid this, TensorFlow does not perform any type conversions automatically: it just raises an exception if you try to execute an operation on tensors with incompatible types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot compute Add as input #1(zero-based) was expected to be a float tensor but is a int32 tensor [Op:Add] name: add/\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tf.constant(2.0) + tf.constant(40)\n",
    "except tf.errors.InvalidArgumentError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot compute Add as input #1(zero-based) was expected to be a float tensor but is a double tensor [Op:Add] name: add/\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tf.constant(2.0) + tf.constant(40., dtype=tf.float64)\n",
    "except tf.errors.InvalidArgumentError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use `tf.cast()` when you really need to convert types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=46, shape=(), dtype=float32, numpy=42.0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = tf.constant(40., dtype=tf.float64)\n",
    "tf.constant(2.0) + tf.cast(t2, tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=48, shape=(), dtype=string, numpy=b'hello world'>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(b\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=50, shape=(), dtype=string, numpy=b'caf\\xc3\\xa9'>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(\"café\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=52, shape=(4,), dtype=int32, numpy=array([ 99,  97, 102, 233], dtype=int32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = tf.constant([ord(c) for c in \"café\"])\n",
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=64, shape=(), dtype=int32, numpy=4>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = tf.strings.unicode_encode(u, \"UTF-8\")\n",
    "tf.strings.length(b, unit=\"UTF8_CHAR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=69, shape=(4,), dtype=int32, numpy=array([ 99,  97, 102, 233], dtype=int32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_decode(b, \"UTF-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String arrays\n",
    "\n",
    "It’s important to note that a tf.string is atomic, meaning that its length does not appear in the tensor’s shape. Once you convert it to a Unicode tensor (i.e., a tensor of type tf.int32 holding Unicode code points), the length appears in the shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = tf.constant([\"Café\", \"Coffee\", \"caffè\", \"咖啡\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=72, shape=(4,), dtype=int32, numpy=array([4, 6, 5, 2], dtype=int32)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.length(p, unit=\"UTF8_CHAR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.RaggedTensor(values=tf.Tensor(\n",
       "[   67    97   102   233    67   111   102   102   101   101    99    97\n",
       "   102   102   232 21654 21857], shape=(17,), dtype=int32), row_splits=tf.Tensor([ 0  4 10 15 17], shape=(5,), dtype=int64))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = tf.strings.unicode_decode(p, \"UTF8\")\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[67, 97, 102, 233], [67, 111, 102, 102, 101, 101], [99, 97, 102, 102, 232], [21654, 21857]]>\n"
     ]
    }
   ],
   "source": [
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ragged tensors\n",
    "\n",
    "Represent static lists of lists of tensors, where every tensor has the same shape and data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 67 111 102 102 101 101], shape=(6,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(r[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[67, 111, 102, 102, 101, 101], [99, 97, 102, 102, 232]]>\n"
     ]
    }
   ],
   "source": [
    "print(r[1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[67, 97, 102, 233], [67, 111, 102, 102, 101, 101], [99, 97, 102, 102, 232], [21654, 21857], [65, 66], [], [67]]>\n"
     ]
    }
   ],
   "source": [
    "r2 = tf.ragged.constant([[65, 66], [], [67]])\n",
    "print(tf.concat([r, r2], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[67, 97, 102, 233, 68, 69, 70], [67, 111, 102, 102, 101, 101, 71], [99, 97, 102, 102, 232], [21654, 21857, 72, 73]]>\n"
     ]
    }
   ],
   "source": [
    "r3 = tf.ragged.constant([[68, 69, 70], [71], [], [72, 73]])\n",
    "print(tf.concat([r, r3], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=235, shape=(4,), dtype=string, numpy=array([b'DEF', b'G', b'', b'HI'], dtype=object)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_encode(r3, \"UTF-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=301, shape=(4, 6), dtype=int32, numpy=\n",
       "array([[   67,    97,   102,   233,     0,     0],\n",
       "       [   67,   111,   102,   102,   101,   101],\n",
       "       [   99,    97,   102,   102,   232,     0],\n",
       "       [21654, 21857,     0,     0,     0,     0]], dtype=int32)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.to_tensor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = tf.SparseTensor(indices=[[0, 1], [1, 0], [2, 3]],\n",
    "                    values=[1., 2., 3.],\n",
    "                    dense_shape=[3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseTensor(indices=tf.Tensor(\n",
      "[[0 1]\n",
      " [1 0]\n",
      " [2 3]], shape=(3, 2), dtype=int64), values=tf.Tensor([1. 2. 3.], shape=(3,), dtype=float32), dense_shape=tf.Tensor([3 4], shape=(2,), dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=310, shape=(3, 4), dtype=float32, numpy=\n",
       "array([[0., 1., 0., 0.],\n",
       "       [2., 0., 0., 0.],\n",
       "       [0., 0., 0., 3.]], dtype=float32)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.sparse.to_dense(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = s * 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unsupported operand type(s) for +: 'SparseTensor' and 'float'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    s3 = s + 1.\n",
    "except TypeError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=315, shape=(3, 2), dtype=float32, numpy=\n",
       "array([[ 30.,  40.],\n",
       "       [ 20.,  40.],\n",
       "       [210., 240.]], dtype=float32)>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s4 = tf.constant([[10., 20.], [30., 40.], [50., 60.], [70., 80.]])\n",
    "tf.sparse.sparse_dense_matmul(s, s4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseTensor(indices=tf.Tensor(\n",
      "[[0 2]\n",
      " [0 1]], shape=(2, 2), dtype=int64), values=tf.Tensor([1. 2.], shape=(2,), dtype=float32), dense_shape=tf.Tensor([3 4], shape=(2,), dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "s5 = tf.SparseTensor(indices=[[0, 2], [0, 1]],\n",
    "                     values=[1., 2.],\n",
    "                     dense_shape=[3, 4])\n",
    "print(s5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indices[1] = [0,1] is out of order [Op:SparseToDense]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tf.sparse.to_dense(s5)\n",
    "except tf.errors.InvalidArgumentError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=330, shape=(3, 4), dtype=float32, numpy=\n",
       "array([[0., 2., 1., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s6 = tf.sparse.reorder(s5)\n",
    "tf.sparse.to_dense(s6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sets\n",
    "\n",
    "Are represented as regular tensors (or sparse tensors). More generally, each set is represented by a vector in the tensor’s last axis.  For example, `tf.constant([[1, 2], [3, 4]])` represents the two sets `{1, 2}` and `{3, 4}`. You can manipulate sets using operations from the `tf.sets` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=338, shape=(2, 6), dtype=int32, numpy=\n",
       "array([[ 2,  3,  4,  5,  6,  7],\n",
       "       [ 0,  7,  9, 10,  0,  0]], dtype=int32)>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set1 = tf.constant([[2, 3, 5, 7], [7, 9, 0, 0]])\n",
    "set2 = tf.constant([[4, 5, 6], [9, 10, 0]])\n",
    "tf.sparse.to_dense(tf.sets.union(set1, set2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=344, shape=(2, 3), dtype=int32, numpy=\n",
       "array([[2, 3, 7],\n",
       "       [7, 0, 0]], dtype=int32)>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.sparse.to_dense(tf.sets.difference(set1, set2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=350, shape=(2, 2), dtype=int32, numpy=\n",
       "array([[5, 0],\n",
       "       [0, 9]], dtype=int32)>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.sparse.to_dense(tf.sets.intersection(set1, set2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables\n",
    "\n",
    "The `tf.Tensor` values we’ve seen so far are immutable: you cannot modify them. This means that we cannot use regular tensors to implement weights in a neural network, since they need to be tweaked by backpropagation. Plus, other parameters may also need to change over time (e.g., a momentum optimizer keeps track of past gradients). What we need is a `tf.Variable`.\n",
    "\n",
    "A `tf.Variable` acts much like a `tf.Tensor`: you can perform the same operations with it, it plays nicely with NumPy as well, and it is just as picky with types. But it can also be modified in place using the `assign()` method (or `assign_add()` or `assign_sub()`, which increment or decrement the variable by the given value). You can also modify individual cells (or slices), by using the cell’s (or slice’s) `assign()` method (**direct item assignment will not work**) or by using the `scatter_update()` or `scatter_nd_update()` methods.\n",
    "\n",
    "In practice you will rarely have to create variables manually, since Keras provides an add_weight() method that will take care of it for you, as we will see. Moreover, model parameters will generally be updated directly by the optimizers, so you will rarely need to update variables manually. On that note, I am questioning how useful `tf.Tensor` is..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = tf.Variable([[1., 2., 3.], [4., 5., 6.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2.,  4.,  6.],\n",
       "       [ 8., 10., 12.]], dtype=float32)>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.assign(2 * v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2., 42.,  6.],\n",
       "       [ 8., 10., 12.]], dtype=float32)>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[0, 1].assign(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2., 42.,  0.],\n",
       "       [ 8., 10.,  1.]], dtype=float32)>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[:, 2].assign([0., 1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'ResourceVariable' object does not support item assignment\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    v[1] = [7., 8., 9.]\n",
    "except TypeError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[100.,  42.,   0.],\n",
       "       [  8.,  10., 200.]], dtype=float32)>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.scatter_nd_update(indices=[[0, 0], [1, 2]],\n",
    "                    updates=[100., 200.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[4., 5., 6.],\n",
       "       [1., 2., 3.]], dtype=float32)>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_delta = tf.IndexedSlices(values=[[1., 2., 3.], [4., 5., 6.]],\n",
    "                                indices=[1, 0])\n",
    "v.scatter_update(sparse_delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Arrays\n",
    "\n",
    "Are lists of tensors. They have a fixed size by default but can optionally be made dynamic. All tensors they contain must have the same shape and data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = tf.TensorArray(dtype=tf.float32, size=3)\n",
    "array = array.write(0, tf.constant([1., 2.]))\n",
    "array = array.write(1, tf.constant([3., 10.]))\n",
    "array = array.write(2, tf.constant([5., 7.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=391, shape=(2,), dtype=float32, numpy=array([ 3., 10.], dtype=float32)>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array.read(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=397, shape=(3, 2), dtype=float32, numpy=\n",
       "array([[1., 2.],\n",
       "       [0., 0.],\n",
       "       [5., 7.]], dtype=float32)>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=406, shape=(2,), dtype=float32, numpy=array([2., 3.], dtype=float32)>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean, variance = tf.nn.moments(array.stack(), axes=0)\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=407, shape=(2,), dtype=float32, numpy=array([4.6666665, 8.666667 ], dtype=float32)>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by loading and preparing the California housing dataset. We first load it, then split it into a training set, a validation set and a test set, and finally we scale it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target.reshape(-1, 1), random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For better performance, you should use a vectorized implementation, as in this example. Moreover, if you want to benefit from TensorFlow’s graph features, you should use only TensorFlow operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def huber_fn(y_true, y_pred):\n",
    "    error = y_true - y_pred\n",
    "    is_small_error = tf.abs(error) < 1\n",
    "    squared_loss = tf.square(error) / 2\n",
    "    linear_loss  = tf.abs(error) - 0.5\n",
    "    return tf.where(is_small_error, squared_loss, linear_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd8AAAEDCAYAAAB0/A4MAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3XmcjeX7wPHPPWNihrFl3yIZIlsqSTKJqCTVV3uoRKpfllSU1i8VUiJEG1KWShJZIiNkKcVXKbLvuzEzZjHL/fvjmmEsY87MnHOes1zv1+u8ZubMM+e5njkz5zrPc1/3dRtrLUoppZTynhCnA1BKKaWCjSZfpZRSyss0+SqllFJepslXKaWU8jJNvkoppZSXafJVSimlvEyTr1I+xBgTbYyxxpgyXtpfV2NMgjf2pZQ6TZOvUgVkjJlgjJl9nvuvykyk1b0flVLKl2nyVSoIGGMucjoGpdRpmnyV8pLzXVI2xlTPvO+qsza/1hiz1hiTbIxZY4xpctZjXWeMWWKMSTTG7DHGjDXGFM/2/ZjM+94xxhwCluchzh7GmM3GmJOZHx8/z/c3ZcZ22Bgz3xhTKPN79Y0xi4wxccaYBGPMOmPMjXn5PSkVDDT5KuWb3gFeAK4CtgKzjTERIAkOWADMAhoCdwGNgE/PeoyHAAO0ADq7slNjzJ3AB8AI4ArgfWCMMeb2zO9fBYwGXgdqAzcB87I9xJfAPuCazJheA5JdPmqlgkQhpwNQKkC0O0/hUkHe3P7XWjsfwBjzCLAbeAD4GHgOmGatHZ61sTGmJ/CHMaactfZg5t3brLXP5nG//YDPrbUfZH69KfOs+wXge6AacAKYZa2NB3YA67L9/CXAO9bafzK/3pzH/SsVFPTMVyn3+Bk508t+e6AAj7ci6xNrbQKwHqibeVcT4KHMy7oJmUk/67JyzWyPsSYf+72ccy9RL8u27x+RhLvNGPOFMaaLMSYy27bvAh8bY34yxrxkjKmTjxiUCniafJVyj0Rr7ebsN+RsNbuMzI8m231h+dhXCHIGnD3RNwRqAWuzbXciH4+dEwuQebZ7JXAPsBMYAPxjjKmU+f3XkEQ9E7gO+J8x5lE3xqFUQNDkq5T3HMr8WDHbfY1y2PbarE+MMUWR8de/M+/6Hah3drLPvCUVMMa/geZn3Xc9sCHrC2ttmrX2J2vtAKABUBRon+37/1prR1prbwM+AboVMCalAo6O+SrlPZuBXcBrxpj+QHVgYA7bDsysUt4LvAKcRIqZAIYAK40xHwLjgHigDnC7tbZHAWMcBnxljFmDFHW1Ax5EirowxrRHLm3/DBwFbgQigb+NMeFIodhXwHagPJK4VxUwJqUCjiZfpbzEWptqjLkPGIMUKa0FXgTOadAB9AeGIxXFfwHtrbUnMh/nf8aYG4BBwBIgFKmI/tYNMc40xvwfUng1AhnffdJa+33mJrFAR+QNQQSwBehmrV2aOZe4FDABObs/knls/Qoal1KBxlhrnY5BKaWUCio65quUUkp5WZ6SrzGmVmZXm8meCkgppZQKdHk98x0N/OqJQJRSSqlg4XLyzSwUiQUWeS4cpZRSKvC5lHwzG7a/AfT1bDhKKaVU4HN1qtF/gU+stbuNMTluZIzpDnQHKFKkSJNq1aoVPEIflZGRQUhIzu9drIUjRwpTpkyKF6Nyj9yOzd8F8vHt2rULay3B/L/n7/zx+JKTQylcOANjLjx7xh+PLS82bdp02Fpb1pVtc02+xphGQGugcW7bWmvHA+MBateubTdu3OhKDH4pJiaG6OjoXLdLTISICM/H406uHpu/CuTji46OJjY2lrVr1+a+sZ8K5OcP/O/4Vq6EevUgMjL3bf3t2PLKGLPD1W1deQsSjXTi2WmM2Y9MmL/bGPN7vqILIseOQYMGkJbmdCRKKeUZEyfC3r1OR+F/XLnsPB6Ymu3rfkgy7umJgAJJqVLw559QSPuIKaUC1NixTkfgn3I987XWJlpr92fdgAQg2Vp7KLefVZCaCi++KGPASikVSO64A/76y+ko/FOez8kylwxTLipWDKpWlUvPYflZPE4ppXzUe+9BANf2eVTglp35CGOgZ0/Yv9/pSJRSyn2++QZKltRhtfzS5OsFSUlw223yUSmlAsGqVTqcVhD6nsULwsNh3To5C1ZKKX+XmgpDhzodhX/TM18vSU+He++Veb9KKeWvrIXGjWHPHqcj8W965uslhQpBt246PqKU8m/GwC+/QPHiTkfi3/TM14tat4bVq3WcRCnlv956S1/D3EGTr5e99x4c0hnSSik/lJ4OF10ERYs6HYn/04ugXmSMlOcrpZQ/OnwYnn3W6SgCg575epm10KYN7NzpdCRKKeW6lBRo2RISEpyOJDDoma+XGQOjR0OVKk5HopRSritcGDZsgABeEdCr9NfogKgo+OornXaklPIPJ09Cly4yv1e5hyZfh2zYAAcPOh2FUkq55q675OxXuYdednbI66/LYgvWaucrpZRvW78eOnRwOorAome+DrrtNlizxukolFIqZ0ePyrKoGRlORxJY9MzXQdOmyaogSinlq0qXhvnznY4i8OiZr4NKloSPP4aNG52ORCmlzrVrF9xyi3a08gSPJd/YWF053hWlSmnpvlLKN1WqBO+8o3Uprvjss7xt77GX/YMHi9Crl7QjUzm7+26oUAHi4pyORCmlTjt+HGbNgnr1nI7Et2VkwIAB8Oijefs5j55zjRwJd9wB8fGe3Iv/GzgQ5s1zOgqllDrtwAGZEqlylpgoS8W+/TaEhubtZz2WfKtWTaR0aZgzB1q0kLEDdX4jRsA99zgdhVJKifR0qFkTXnrJ6Uh81/79cOON8PXXsrziDz/k7ec9lnzDw9NZtUq6Oa1bB02b6rSanBgDkybBF184HYlSSsGCBdC5s9NR+K4//5Sctno1VK8u6xvffHPeHsOjl50vuwxWrIDoaNi3T86AZ8705B7919VXw3XXOR2FUkpJhfPYsU5H4ZvmzZPX6p074dprYeXK/I2Le7zONmuOWNeukJQkLcreeUdL1892+eWnG5crpZRTVq2SHgTFizsdie8ZM0aaI8XHy1DhTz9B+fL5eyyvTHK56CL49FN4801Jus89Bz16aJPusy1fDjExTkehlApmEREyBVKdlp4OffrAU09JdfPAgTBlCoSH5/8xvdbhyhgpx77sMhlL+Ogj2LpVBqu1y5Po1Ek+ar9npZQTDh+WQqv69Z2OxHckJMD998Ps2RAWJrmrS5eCP67X2zt06iRnd+XKwaJF0KyZJGElfvgBevZ0OgqlVDD66it47z2no/Adu3dLrdLs2XI14Mcf3ZN4waHezk2byrhC+/bw11/y9XffacERyBN97bVOR6GUCkY9e2o9Tpbff4fbb4e9e6FWLUnAUVHue3zHGhtWry5jnG3byqWOVq3kGnqwi4yUyxzffON0JEqpYDJypJwE6ZCX/B5atJDEe8MNMmvHnYkXHF5YoUQJeTfRsyekpMADD8Abb+g7r/R0udyhlFLe0q4dNGrkdBTOshbefRfuvFO6V3XuLHOeL77Y/ftyvKV/oUIwerSMMxgDr74qB5yS4nRkzqlRA3r1kt6qSinlaatXy5jmJZc4HYlzUlPlRPDZZyUJDxoEEybIFFBPcDz5giTd3r3lVL9oUZg8GVq3lsvRwWrbNrkUH+xXAZRSnjd/Pvz7r9NROOf4calBGjdOku3UqdJa05OX4H0i+Wa5/XZYuhQqV4Zly6TwKFjXuq1RQ8YZdPxFKeVJGRnw8svBW/C6fbsc+4IFULYsLF4siyV4mk8lX4DGjaUSunFj2LJFEvDixU5H5YyTJ+Hxx3VZRqWU59x0k8w6CUYrV8psmw0boG5dyT3Nmnln3z6XfEHOfJcuhQ4dIDZWGlbndaHiQFC0qBRBZGQ4HYlSKlBNmyaJJ9hMny6rEh08CG3ayOybGjW8t3+fTL4giWfGDBn8TkuThYoHDAiuRGSM9MJes0bHfpVS7jd0qIxxBtPwlrXS6vjeeyE5Gbp3l6Vvvd1p0WeTL8jixO+8Ax9+KJ+//bb8whITnY7Mu4YOlbUjlVLKXdLSJBEVLep0JN5z8iQ88sjpYqrhwyW/hIV5PxafTr5ZevSAuXNllY2vv5ZLBcGSjIyRKwAVKjgdiVIqkBw8CC+8INM9g8HRozKEOXGiLB4xYwb07evcWb9fJF+Qa/IrVkhnrNWrZZB8/Xqno/Kee+6B335zOgqlVCA4elTW7E1LczoS7/j3XyneXbIEKlaEn3+Gjh2djcml5GuMmWyM2WeMiTPGbDLGdPN0YOdTt65Up117rSxk3Ly5LGwcDIYNgyuvdDoKpVQgKF0a1q4NjrPen3+WnPHvv9CwoZy8NWnidFSun/m+BVS31hYHOgCDjDGOhF++vCxgfO+9sqDxbbfJAseBrnp1WfEoWOc9K6XcY+tW6NYtOIqsJk2Shk1Hj0oTjWXLoEoVp6MSLiVfa+1f1tqsho8281bTY1HlIjwcvvxSFjTOyJAFjnv3Dvz5sMePyxsOpZTKrwoV4LHHnI7Cs7Iah3TpIm0je/WCmTOhWDGnIzvNWBfnsBhjxgBdgXDgD+AGa23CWdt0B7oDlC1btsn06dPdGuz5zJ9fnnfeqU1aWgjNmh1m4MC/iYjwfBZOSEigmAPPZHq6ISUlxKPH6NSxeUsgH1/v3r1JT09n1KhRTofiMYH8/IFnj+/YsTD27Qunbt04jzx+brzx3J08GcLbb9dh8eJyhIRYnn76X+68c69H95nlxhtvXGOtvcqlja21Lt+AUOB6YCAQdqFto6KirLcsWWJt6dLWgrUNG1q7a5fn97l48WLP7+Q8Bg2ydvhwz+7DqWPzlkA+vpYtW9qGDRs6HYZHBfLzZ61nj2/FCnkNcYqnn7sDB6xt1kxyQWSktXPnenR35wB+sy7m0zxVO1tr0621y4AqQM88vSXwoBtukEKsWrVg3Tq45hppTBGInn9eyuOVUiov0tKk8Oill5yOxDM2bJBZMCtWQLVq0rGqXTuno8pZfqcaFcLBMd/zqVVLEnDLlrBvnyTkmTOdjsr9wsLkj2rIEKcjUUr5k/ffl0ZFgejHH6Un8/btcPXV0qO5fn2no7qwXJOvMaacMeY+Y0wxY0yoMaYtcD+wyPPh5U3p0rIyRZcu0gXrrrukg0mgtWa89FKIjnY6CqWUP+nVS9arDTQffSRzluPi4O67ISbGP5oSuXLma5FLzLuBY8A7QG9r7SxPBpZfF10kizAMHixJt18/eOIJqXgLFBUryru6pUudjkQp5Q8mToT//Q9KlHA6EvdJT4fnnpPezOnp0L+/LJYQEeF0ZK7JdYq1tfYQ0NILsbiNMfDii3DZZXIWPH68zG376ivvN8/2lCNH4NNPoUULpyNRSvm60qUDK/GeOAEPPSRDi4UKSX9mf5s+5TftJfPjnntkLeBy5WDhQlkweds2p6Nyj6pV5Qw/0Oc2K6UKZuNGaUZU06eqdPJv716p7Zk5U06m5s/3v8QLAZ58Qar7Vq2CevXg779PV8MFgqQkuOKK4FvlSSnlumefhS1bnI7CPdatk9fwNWuk9mXFCmjVyumo8ifgky9Ia8bly2VFi0OHZFWkqVOdjqrgwsNl3NdfxjiUUt43e7bMBvF3c+ZIP//du+XjqlVQp47TUeVfUCRfkPGOOXOk+ColBe6/HwYN8v9K6DJl5DiOHnU6EqWUL0lMhOuvD4wrYyNHQocOMtb7wAMyjFimjNNRFUzQJF+QgfkxY+C996QoK6v3Z0pK7j/ry6pVC56lwZRSromIkGJTf74ylpYGTz8t06QyMuC112DyZChSxOnICi6oki9I0u3dWwbrixaFzz+XtYKPHHE6svzr3Fn+MI8fdzoSpZQvOHECPvlElmH1V3FxcrY7erRMIZ08GV59NXBWYwq65JulQwcZL61UST5ee61/L9f35pvwyy9OR6GU8gVHj8Lhw05HkX87d8ol87lz5fLyokXw4INOR+VeQZt8ARo3loWVGzeGzZulPVlMjNNR5c/IkdLlRSkV3JKT4eKL4YUXnI4kf379Vfrzr18PtWtL2+Drr3c6KvcL6uQLULky/PyznAkfOyYV0Z995nRU+TNpEgwd6nQUSiknLVgg46T+6JtvZA7vgQMyK2XFisCZn3y2oE++IAssz5ghqwWlpsKjj0qHrIwMpyPLm9atJXalVPDq0AHGjXM6iryxVk4c/vMf6V/w2GMwbx6UKuV0ZJ6jyTdTaKgswjB2rHz+1ltw773yh+AvKlWSyu2vvnI6EqWUE0aOhFmzZPUzf3HyJDz++OnL5EOGyGIJF13kbFyelmtv52DzxBPSOaVTJ/j6axn4nzULypd3OjLXZGTIslpKqeDTtq1/TcM5dkzOdn/6SeKePFlWJgoGeuZ7HjffLJXDl1wiBVlNm8KffzodlWuqVpWVPg4ccDoSpZQ3zZ8vJwmXXOJ0JK7ZskWKXH/6SeJesiR4Ei9o8s1RvXrSvqxpU9ixQxZlmD/f6ahck5AAN90kVY9KqeCwYIHMjfUHy5efnt5Zv76c5FxzjdNReZcm3wsoX15WRbrnHoiPl5VBxo51OqrcFSsma3f60+UnpVT+nTghNSvVqjkdSe6+/FIWQzh8GNq1g2XL/CNud9Pkm4vwcJgyBV56SZbve/JJ6NPH95fyCwmBrl39u3GIUip38fHQqJHvX+myFiZOvIQHH5Qiq6eegu+/h+LFnY7MGZp8XRASIosXTJggVYQjRsArr1xBQoLTkV3Y00/Lik5KqcAVGSlL7fnyla6UFHj4YZgwoQYhIfD++/DBB9JvP1hp8s2DLl3gxx9l7tkvv5ShRQtZ3spXXXWVrHv5999OR6KU8oRNm6B/f99ePOHwYelB8MUXUKRIOt99B88843RUztPkm0ctW0q7sypVElm7Vgqyfv/d6ahytnUr7N3rdBRKKU8oU0ZmZ/iqf/6R18hly6BKFRg16g/at3c6Kt+gyTcfoqLggw9+54YbJLG1aAHffed0VOf30ENS3KArHikVWDZvltXYWrVyOpLz++knmUq0dStceaXMHrnsMh8fq/MiTb75VKJEGgsWyKXoxES48054910pKvA1M2fCs886HYVSyp3WrvXdhWA+/VQafsTGwh13SP/8SpWcjsq3BPFwd8EVLiyLMNSqBQMHSoLbtAlGjfKt9m4dOshNKRUYTp6UzlC+JiND+uIPGSJf9+sHb78tLXvVmfTMt4CMkWlI06ZJMh43TuYD+9Jl3tBQKXp44AH/WyxCKXWu++/3vbPexETpiTBkiLzmjBsHw4Zp4s2JJl83uece+WcoW1Yqoq+7DrZtczqq08qVg27d5M2CUsq/TZwotSa+Yv9+iI6WJQGLF4e5c6F7d6ej8m2afN3o2mulqKBuXdiwQar8VqxwOiphjBRmTJ/uXys1KaVOS0uDHj3kc185o1y/Xl7rfv1V+gqsWAFt2jgdle/T5OtmNWrIogxt2sChQ7Ig9LRpTkd12p9/6qILSvmzNm2gaFGnoxDz5kHz5rL6W/aTD5U7Tb4eUKIEzJkj71BTUuC++6RDli9UQv/3v1J1GB/vdCRKqbw4cULe2P/nP74xfDRmjNS3xMfL2uc//STDW8o1mnw9JCxMFmEYPlz+UV5+WXotp6Q4HZkk4MmTnY5CKZUXW7dKL2SnpadD797SmzkjQ2Z6fPml9MFXrtOpRh5kDPTtCzVrSqXxpEmy0P2MGXDxxc7F9eqrwd1TVSl/k5wMV1wh1cNOSkiQSuvZs+UE4+OPoXNnZ2PyV3rm6wV33AFLl8rl3p9/lrGRTZuci6dQIWmJ+dRTzsWglHLdO+/Igi5O2r1bKqxnz4bSpWHhQk28BaHJ10uy2qs1aiRt4Zo1gyVLnIunTh2ZeqSU8n0DBpyucnbCmjWy2P3atdJUaOVKuOEG5+IJBJp8vahKFTkDvv12OHpUqhYnTnQmlogIqFdPLhv5QiGYUur8nnkGduxwbuWi776TRLtvn3xcsUISsCoYTb5eVqwYfPst9OkDqalShDVwoDOdp0JD5fJ3YqL3962Ucs2tt8obd2+zVgpG77xTXiOyllR1sl4lkGjydUBoqCzCMGaMfD54sBQxeLv5RWgoDB0q+z150rv7VkpdWFqaNMVp2xYuusi7+05NhZ49pTeztTJV8rPPvB9HINPk66CePWU+cGSk/JPdeKMzDTB694bly72/X6VUzg4dkrFVbzt+XObvjhsn/eqnTZP+9b4wtziQaPJ1WNu2MnH+kkukIKtpU/jrL+/GMGmSJH6llG9ISIBSpeQKmTeT3rZt0pf+xx+lT31MjPStV+6nydcHXHHF6cS7Y4f88c+f7739h4TIGXjfvt7bp1IqZ9Ony3x8b1qxQl6DNmyQFpGrVsm0SOUZuSZfY0xhY8wnxpgdxph4Y8xaY8wt3ggumJQvD4sXQ6dOEBcnl30+/NB7+7/+ehnfUUo579FHZZzVW6ZNk6tfhw7JLIxffpE+9cpzXDnzLQTsAloCJYCBwHRjTHXPhRWcwsNh6lRZjDo9XcaE+/aVzz2tRAkZe37zTZ16pJSThg6tzdq10kHK06yVgs/77pPWtz16yFWwEiU8v+9gl2vytdaesNa+Zq3dbq3NsNbOBrYBTTwfXvAJCZF/hs8+k3++996Du+6SMSBPi4iQAou0NK2sUMopd9+92ysrA6WknJ7qaIxMKxo71jtJX+VjzNcYUx6IArxcFhRcunaFBQuk6GLWLGnrtnu3Z/cZGgrPPgv79oXr3F+lvCwlRRJg9eonPD6l58gRuPlmKbaMiJDeA337akWzN+Wpvb4xJgz4Aphorf3nPN/vDnQHKFu2LDExMe6I0SclJCR45fjefz+cAQPqs3ZtBI0bp/Dmm+upVcuzp8FTptQgIWENdesG5rqD3nrunBAbG0t6enrAHh8E7vMXF1eILVsqULu2Z49v9255Tdm9O4IyZVIYPHg9JUok4I1faaA+d/lirXXphpwlTwV+AMJy2z4qKsoGssWLF3ttX4cOWduihbVgbUSEtd9959n9ZR1bSopn9+MUbz533tayZUvbsGFDp8PwqEB8/vbvt/bAAfnck8cXE2Nt6dLyWtKwobW7dnlsV+cViM9ddsBv1sWc6tJlZ2OMAT4BygN3W2tTPfReQJ1HmTIy7+7hh6XNW8eOMhbsycKomTPhySc99/hKqdMWLYKPPvLsPiZNkkrmo0ehfXtYtsyZtpVKuHrZeSxwOdDaWuvlJogKpBBq4kSIioKXX5bxmU2bYNQoz6zNe+utMiaklPKstDRZ79tTMjJkznDW1KXevWWJwtBQz+1T5c6Veb6XAD2ARsB+Y0xC5u1Bj0enzmCMVCZOmSLJ+MMPZT7w8ePu31dWwceDD3q/57RSwaRtW1i/3jOPnZQkiX3QIJlJMXq0XDXTxOu8XM+ZrLU7AK2B8yH33SftKO+4QyqimzeXBa6rV3fvfiIi5FK3NlNXynOmTpWhJXc7eFBeI1auPN0/vl079+9H5Y+2l/RTzZpJ+7fLL5de0E2beqYJe7t20t9161b3P7ZSwWzXLnjqKUm87p7is2HD6deEatVk4RRNvL5Fk68fq1FD2sC1aSPvcm+8Ud7dutv27c6stqRUICtdWtbKdXfi/fFHeXO+fTtcfbW8Sa9f3737UAWnydfPlSwp7eC6d4fkZLj3Xve3iHzsMXkXvW2b+x5TqWC2bBns3AmtW7v3ccePh1tukf7w//mPXLWqUMG9+1Duock3AISFSfHV8OHyLvqll+CRR+DkSfftY+1aXXhBKXfZuRP27XPf46Wny/9njx7yef/+slhCRIT79qHcywOTVJQTjJHpR5deKhXKEyfKZadvvoGLLy744195JXz9tfxja6WkUvm3bZt7pxadOCH/8999J9MOx42TVZGUb9Mz3wDTsSMsXQqVKsGSJTL28++/7nv8Vq1kfrFSKu9OnpTF6WNj3fN4e/fCDTdI4i1ZUmY/aOL1D5p8A9CVV0qRRcOGknivvVYScUEZIwVdUVEFfyylgk1GhpyZrl4tibKg1q6Fa66B33+HmjVhxQopulT+QZNvgKpSRYo62reXdnJt2kh7uYIqXx7mzZPJ+kop102fLquGuaO6efZsuP562LNH5vmvXAl16hT8cZX3aPINYMWKSY/m3r0hNRW6dJEOWRkZBXvcOnXkH18p5bpOnaQYsiCshfffl+YZWWO9ixZ5pkmH8ixNvgEuNFTayY0eLZ8PHizFHgVpGVm9ujT3+Phjzy7uoFQgsFaaaWzbVrAkmZYG//d/8mY6IwNefx0+/1xazSr/o8k3SDz5pFyqioyUKQitWkljjvwKCYHNm2WVJaVUzoyRZhrVquX/MeLi4Pbb5U30RRfBF1/AK6+4v0GH8h5NvkGkXTtpM1etmowRNW0qrSnzo1AhePttSEiA/fvdG6dSgeLIEZn217p1/nuk79gh47rz5smZ808/eXYVJOUdmnyDTP36Ugl9zTUyD/i666QdXX5NnFiwn1cqkMXGyllrfv36q7xJ/vNPqbVYuVISsfJ/mnyDUIUKsHixtJ+Li5N2dOPG5e+xnn9eVj46ccK9MSrl79avl/n2//d/+fv5b76Bli2lr3qrVtLHvWZN98aonKPJN0hFRMjY74AB0rXqiSdkGkR6et4f6+BBmUuclub+OJXyVx99BH/8kfefsxaGDJE3x0lJ0lt93jwoVcr9MSrnaHvJIBYSIosw1KolCzO8+y5s2QI9euTtPVm5cnI5rJD+NSkFyOXmkSPz/nMnT8I779Tmhx/k6yFD4LnntLAqEOmZr+KRR6QtXalS0qauV6/G7NmTt8coWlSqL2fM8EyMSvmLjRuluU1ep+EdOyZFkT/8UJHwcLns/PzzmngDlSZfBUhbuhUrZEzp338jado075fMunSBtm09E59S/sBaqF1bGl/kJWlu2SJ92BcvhtKlU1iyBO66y3NxKudp8lWn1K4tl48bNIhlzx5o0QK+/971n69ZU6YePf+8Nt9QwenJJ2H+/Lw1vli2TCqaN26U2QhjxvzO1Vd7LkblGzT5qjOUKQPDhq3joYekgvmOO2DECNeTael9S763AAAdhUlEQVTS0KiRZ2NUyle9/LKsMuSqL76Am26S+cC33CKJuHz5FM8FqHyGJl91josuskyaBG+8IUm3Tx9pj+dKNXNYmDQAWLhQOmApFQx274aePaFiRQgPz317a+G11+Chh6TI6umnYdYsKF7c46EqH6HJV52XMfIu/ssv5RLa2LFSRHL8uGs/v3s3HDrk2RiV8hUXXywtJF0Z501OlqT7+usy42DkSBg1SmcLBBtNvuqC7r9f2tmVLStjWc2bS2es3DzyiIxj/fqrx0NUylFffgm7dsHNN+e+7aFD0mryyy9l1bFZs/LfhEP5N8fea8XFxXHw4EFSU1OdCqFASpQowd9//+10GB5x9rGVKxfG0qXluPPO4vz1lyTVWbPk44UcPAiDBsn0o9BQDwetlEOSk2W4JTf//AO33QZbt8p627NnQ8OGno9P+SZHkm9cXBwHDhygcuXKhIeHY/xwIlt8fDyRkZFOh+ER2Y/NWktSUhJ79uxh4ULo0qU4CxdCdDRMmiRrlOakQgWZN5yQIGNcAfrrUkEqOVkWKnn00dy3/eknuPtuab7RpInMIqhY0fMxKt/lyGXngwcPUrlyZSIiIvwy8QYTYwwRERFUrlyZxMSD/PADPP64vPDccw+89VbuldBDhsD06d6JVylv2bFDzl5z88knMv89NhY6doQlSzTxKoeSb2pqKuGulAQqnxEeHk5qaiphYbIIwzvvSHHJiy/KO/+TJ3P+2ddek/60F9pGKX+yaZO0ZX3vvZy3yciA/v2hWzeZKfDcc9K1qmhR78WpfJdjBVd6xutfsj9fxsgiDDNmyAINEyZIscnRo+f/2dBQufTcuLGufqQCw0svyTJ/OUlMlCtDQ4bI3//48TB0qFQ3KwVa7awKoGNH+PlnuYS2ZIm0x/v33/NvW6yYNBAoWlS7Xyn/lZYmy3BOnw4NGpx/m/37pSbim2+gRAlZkejxx70apvIDmnxVgTRpAqtXS9Xmpk2ytODSpefftlQpmWLxxhvejVEpd/nhB+jbN+f5vOvXn55iV6OGrMHburV3Y1T+QZOvKrAqVSTh3nabXHq+6Sb4/PPzb9uunawdrJS/SUuDDh1gzJjzf3/uXJkHv3OnXAVauRLq1vVujMp/aPLNo+joaJ5++mnHHyM3x44do3z58mzZsiXXbTt16sTw4cMLtL/IyKzlCCE1FTp3liUGz77EXLq0rP/7yCNSLaqUP0hLg6uvhsOH4aKLzv3+6NHSAS4+Hu67T6YWlSvn/TiV/9DkG6DefPNNbr31VmrWrJnrtq+88gqDBw/muKu9I3MQGiqLMHzwgRSW/Pe/0uc5OfnM7YyR5FupUoF2p5RXWCutH+fPl4VHsktPh969pTdzRoa0ZP3iCyhSxJlYlf/Q5BtATmbO5UlMTOTjjz/msccec+nn6tevz6WXXsrkyZPdEsdTT8n8x8hImDoVWrWSblfZ3XCDnPm++aZbdqmUxwweLBX9Z5/JxsfLql/vvy8drrIWI9GKZuUK/TPJh4yMDF5//XXKlClDuXLl6NevHxkZGcD5Lyl37dqV9u3bn3FfWloavXr1olSpUpQqVYrnnnvu1GOAdJYaOnQoNWvWJDw8nPr165+THKOjo+nZsyf9+vWjbNmyNG/eHIAffvgBY8yprwGGDh2KMeac2yuvvAJAhw4dmDJlitt+R7fcIt1/qlWDFSukCGXDhjO3KVtW5koq5cueeELGerPbvVvWu54zR4ZSFi6Ehx92Jj7ln3wi+RrjzC2/vvjiC0JDQ/nll1/44IMPGDFiBNOmTcvzY2RkZLBixQrGjRvH+PHjGTFixKnvDxw4kE8++YTRo0ezYcMGBgwYQI8ePZgzZ84ZjzN58mSstSxdupRJkyYBsHTpUpo0aXLG3NyePXuyb9++U7dnn32WChUq0LlzZwCuueYaVq9eTVJSUn5/LeeoXx9WrZKxsu3bpQjlxx9Pf79ECWlPOWMGrF3rtt0q5RZbt8KDD8qKRaVLn75/zRq45hpYtw6ioqSwKi9r+CoFDi6s4M/q1q3LwIEDiYyMJCoqio8++ohFixZx//33u/wYFStWZOTIkRhjqFOnDps2beLdd9+lb9++nDhxgnfffZcFCxbQokULAGrUqMHq1asZPXo0t91226nHqVGjxjnFUjt27KDSWQOqkZGRp/o1DxkyhClTphATE8Nll10GQKVKlUhNTWXv3r2Uc2OlSIUKEBMjBVjffCNnxGPGQPfup7cJDdW5v8r3VKsmBYTZ36jPnCkJOTHx9Fze7IlZKVf5xJmvtc7c8qvBWbPrK1WqxMGzBzVzce21155xZtqsWTP27NlDXFwcGzZsIDk5mXbt2lGsWLFTt7Fjx55TvdykSZNzHjspKYkiOVR8vPXWW4waNYrFixdTu3btU/dntft055lvlogIaUrQv78UqPToAf36yecg42YNGsBHH0lVqVJOslbm8u7YIWe4WfcNHw533SWJt0sXKcDSxKvyy6UzX2PM00BXoD4wxVrb1YMx+byws9YPM8acGq8NCQnBnpXZ87psYtZjff/991SrVu2C+y56nkaxZcqU4dixY+fcP2jQID788MMzznizHM3sDVm2bNk8xeqqkBBZhKFWLUm+w4fDli0wefLprlfbt0v7yRIlPBKCUi4xBtq0gcqV5evUVKlmHj9evn7zTXkjqR1yVUG4eua7FxgEfOrBWAJC2bJl2bdv3xn3rVu37pztVq1adUaSXrlyJZUqVaJ48eLUrVuXwoULs2PHDi677LIzbpdcckmuMTRu3JgNZ1U3vfHGG4wfP54lS5ack3gB/vzzTypXrkz58uVdPdR8efRRWLAASpaUS3g33AB798pUjsGD5cx30SKPhqBUjmbOlBqEW26R6UKxsXDrrZJ4ixSRKzgDBmjiVQXnUvK11s6w1s4Ejng4Hr/XqlUr5s6dy6xZs9i4cSN9+/Zl165d52y3d+9eevfuzcaNG/n6668ZNmwYffr0AWR8tl+/fvTr149PP/2UzZs3s3btWj788EPGZ739voC2bdvy999/c+SIPF2DBg1i5MiRTJ06laJFi7J//372799PcrYJuEuXLqVt27Zu+i1c2I03SpFKzZrw++9yaS+r4GrPHukBrZQTLr0UqleXz7dtk45VCxfKNKOYmAuvX61UXri14MoY0x3oDnIGGBMTc97tSpQoQXx8vDt37TXp6emcPHmS9PT0U8eQmppKWloa8fHxdOrUid9++41HHnkEgMcff5z27dtz5MiRU9unp6dzzz33kJSURNOmTTHG8PDDD9OtW7dT2zz//POUKFGCoUOH0rNnTyIjI2nQoAG9evU643FOnjx5zu+yevXqNGnShAkTJvD4448zbNgw4uLizph6BDBr1iyio6NJTk7m22+/ZcaMGcTHx59xbNklJyfn+Jzmx/DhYbz8cj3Wry9Js2bpvPLKBpo1O0LLlvDxx8UoXjyVcuVS3La/LAkJCW49Dl8SGxtLenp6wB4feOb5i40N47vvKtG58w6MgdGjizNw4BXExl5E9eoneOut9SQlJeONX2sg/30G8rHlmbXW5Rty6XmCK9tGRUXZnGzYsCHH7/mLuLg4p0O4oLlz59qoqCiblpaW67YffPCBbdOmzamvczo2TzxvycnWPvSQlMCFhFg7YoS1GRnWjhxp7dy5bt+dtdbaxYsXe+aBfUDLli1tw4YNnQ7Dozzx/B09au3EifL51KnWFi4sf5M332xtbKzbd3dBgfz3GcjHZq21wG/WxXzqE9XOyv3atWvHU089xe7du3PdNiwsjFGjRnkhqnMVLiydgV5/XdrzZbXq69lTFmFYtOh0VbRS7matFAJaK00yBg2S3swpKdJcY84cLQBUnqHzfAPYM88849J23bNPunWAMbIIQ61a0LWrzAPeuhWmTJFq6Dp1TleeKuVO1kobVGPkb2/SJPn83XfPneOrlDu5OtWoUOa2oUCoMaYIkGat1VmZym3uv18aG3TsKAuQt2ghPaLLl5dil+hopyNUgeSLL+Dyy+XvrmNH+PlnmZM+Zcq57SSVcjdXLzsPBJKA/sBDmZ8P9FRQKng1by4tKevUgT//lJ7Qc+dKY3vtgqXcqVgxWfDj2msl8VaqJOtSa+JV3uDqVKPXrLXmrNtrHo5NBalLL5XFGG66CQ4cgHvukbVSDx2CX391Ojrl7/73P7m8XLKktIrcvBkaN4bVq+HKK52OTgULLbhSPqlkSTnj7dZN1gPu1AleegkWL3Y6MuXvihSRxRHatIGjR+H22+XMV+sKlDdp8lU+KyxMOgsNHSqFLx9/DP/8I004XCjiVuoM+/fDiy/CxIkwcqS0jezTB779Vi5BK+VNmnyVTzMGnntOVo8JD4fPPoNHHoHffnM6MuVvChWSKydvvikraY0ZI1XNoaFOR6aCkSZf5RfuvFMuDVaoIGN0L7wgL5zHjzsdmfJ1KSmypGW7dtLWNDJS5u/27Ol0ZCqYafJVfuOqq6QopkED2LQJBg6EH390Oirl6/79V6aurVkDl1wCv/wCXmpjrlSONPkqv1K1qoz53norJCXBAw9INbQHliFWAeCWW2Qq0aFDMm1t1Sq44gqno1JKk2+e3XnnnZQqVYqHH37Y6VCCVmQkfPcdPPOMFM189ZW0BdR5wCqLtTBunCxfeeKEVMsvXiwNW5TyBZp886hXr15MmjQpzz+3a9cuoqOjqVu3Lg0aNOCrr77yQHTBo1AheP99GDUKQkKkiKZOHXmhVcEtPV3m6z7xhPQLf/FFmDpVCvaU8hWafPMoOjqayMjIPP9coUKFGDFiBBs2bGDBggX07t2bE5opCuzpp+H776FoURkHvvlmucSogtPx43DXXbI+dKFCUh0/eLC8QVPKl+ifpJdUrFiRRo0aAVChQgXKlCnD0aNHHY4qMNx6qxTRVK0qH2vUgL//djoq5W179kiv5lmzoFQpKcbr2tXpqJQ6P02+DlizZg3p6elUrVrV6VACRoMGUkxz1VVy6blZM5g/3+molLesWCHP/b59ULOmTCnShTiUL9Pk62VHjx6lc+fOjB8/3ulQAk7FirBkCdx9t1x+vOUW+Ogjp6NSnvb995Jo9++XlbBWroSoKKejUurCNPm60dChQzHGnHN75ZVXAEhJSaFjx47079+f6667zuFoA1NEBEyfDs8/LxWv3bvDk09K4Y0KLNZKlXuHDnDyJDz0kFxqLlPG6ciUyp0m3zxq3bo1nTp1YsGCBVSpUoUVK1ac+l7Pnj3Zt2/fqduzzz5LhQoV6Ny5M9ZaunbtSqtWrXSakoeFhMCQIdILOiQExo6Vs2GtbwscaWlSbPfyy/L1f/8rKxUVLuxsXEq5qpDTAfibhQsXAhAfH39O1XNkZOSp+4YMGcKUKVOIiYnhsssuY9myZUybNo0GDRowc+ZMAD7//HPq16/v3QMIIo89JsVXd90FM2fKmOCiRU5HpQrqxIlQoqNh+XJJtp99Bvff73RUSuWNJl8PeOuttxg9ejSLFy8mKnPw6frrrydDr316XatWMgbYqpWsiNS0Kbz6alEtxvFTO3bA0083Zvt2KF5clp3UERzlj3zmsvNrr8kNpFhi0ybpxdqkidz37LMwfLh8XqkS7N0LMTGnKxq7d5fl50A6IMXHSyHG7bfLfQ88AF9+KZ8bk78Ys4/jFi9e/JyxXYBBgwYxevRoYmJiTiVe5aw6dWQB9ebNZSnCJ5+8kjlznI5K5dXq1dCoEWzfXozLL4c//tDEq/yYtdYjt6ioKJuTDRs25Pg9X7Zz507bsmVLe/nll9t69erZ6dOnn/H9119/3VatWtVu3rzZoQjdIy4u7rz3++vzliUpydrHbt5pq7DTGmPtu+86HZH7tWzZ0jZs2NDpMNxuwgRrCxe2tgo77U1Rf9pjx5yOyHMWL17sdAgeE8jHZq21wG/WxRzpM2e+/iB7l6qZM2ee0aVq0KBBjBw5kqlTp1K0aFH279/P/v37SU5OdjhqlaVIEfhoXlVad03DWujbV4p20tKcjkzlJC1NnqeuXWVpwFu7V6X/6MOULOl0ZEoVjCbfPMjepap8+fKnulRZaxk2bBhHjhyhefPmVKxY8dRt+fLlDketsjPTp9Gv6mdMmgRhYTB6tKx6s2+f05Gpsx0+DNdfD++9J60iR4+Gca2mUfFnrZpT/k8LrvLpjz/+OKNL1XFd1d0/jB1L5dhY6q19g5o1ZY7omjXQuDFMmwYtWzodoAL4/XeZHpZVWDVnjiRiouX54403nA5RqQLRM998OHr0KD169NAuVX7uuuvgr7/gxhvhwAH5OHSoLk3oJGtltaqrr5bEe/XV8hxdf73TkSnlXpp88yirS1WfPn20S1UAKF9e1nzt00de+F94QdpSHjzodGTB58gRaN0aeveWjmSPPQY//wxVqjgdmVLup8k3D2y2LlX366z+gFGoELz7Lnz3nVzinD8frrgCnY7kRUuXyjSin36S5SG/+UY6lBUp4nRkSnmGJt88WL58OdOmTWPmzJk0b96cRo0asX79eqfDUm7SoQOsXy/N+Q8dgvbt5ewrMdHpyAJXUpLM4b/hBpmD3awZ/PmndCVTKpBpwVUeZO9Sdb72ksoPfP01fy1fTvMcvl2tmjRvGTYMXnwRPv1ULn1+9pmOO7rbL7/Agw/K2K4xkoTffFOq0HOUy/OnlL/QM18VXMqUIbVEiQtuEhIiY7+//w716sHmzXI2/MQTEBvrpTgDWGIi9OsnHce2b4fatWUt5mHDckm84NLzp5Q/0OSrgsuECVSYN8+lTRs2hN9+gwEDZFx43Di49FIZj9SK6LyzVsbVa9WSVrHGyJuctWulqtkleXj+lPJlmnxVcMnji3eRInIpdO1aaNAAjh2D//xHeor//bfnwgw0mzfLHOqOHaUv+2WXyYIXb7+dx6IqTb4qQGjyVcoF9epJI/+xY6Ua9+efoX59aU95+LDT0fmu48fh+eehbl2paA4Ph5Ej5Y3LNdc4HZ1SztHkq5SLQkJk3HfrVujRQ+aijh4NNWvKZdSkJKcj9B1JSfI7ufRSGctNTYUuXWDbNvi//5PL+EoFM8eSr9VBM7+iz9dp5crBhx/CunVSiBUXJwVEVarAiBHBnYRTU+GTT+QNSb9+cPSoFFb98gtMmCBNTZRSDiXfsLAwkoL5FcoPJSUlEZZrKWpwqV8fliyRZhy1akmi6dMHKlSQph2ZC14FhYQEeeNRuTJ06yYLVURFyWL3S5fK/F2l1GmOJN9y5cqxZ88eEhMT9YzKx1lrSUxMZM+ePZQrV87pcAruhx/439tvu+3hjIFbb4WNG2HWLBnbjIuTOasVKkCvXjKdJlAdOAADB8oZbZ8+0pykalWYMkXGddu1k9+R27j5+VPKKY6MvBQvXhyAvXv3kpqa6kQIBZacnEyRAO19d/axhYWFUb58+VPPm1+LiCDDA8+bMXD77dIVa84cGDxYqnlHjoRRo6BVK+jfXz6G+HmlRUYGLFwoxzZvHqSny/1XXQUvvyy/A48do4eeP6W8zbGyh+LFi/v1i3lMTAyNGzd2OgyPCORjY8wYKm3aJHOFPMAYST7t28Pq1ZJ4p0yBRYvkVrYsdO4si8NfcYVHQvCYzZth6lRJuocOyX3GwB13wHPPydiux3n4+VPKW7TmUAWX6dMp56U2VddcA59/LtW+48dLIdLOnVIFPHy4zHXt0kUuWzdu7ObLs26yYQN8/bW8gfjnn9P3V6oEPXvCI4/IOK/XePH5U8qTXLo4ZIwpbYz51hhzwhizwxjzgKcDUypQVKgAr7wi02yWLpVpSsWKyZnkyy9DkyZQsaIs4vDVV9KEwin790uifewxeXNQrx68+qok3iJFpBfz/Pmwa5eM9Xo18SoVQFw98x0NnATKA42AOcaYddbavzwWmVIBJiREFme4/npZMH7+fJg9W84sDxyQRRw+/VS2LVdOLuO2bCmdterUkSTuzrPjI0dkutQff0gHr8WLYc+eM7eJjJSx7AcfhJtugsKF3bd/pYJZrsnXGFMUuBu4wlqbACwzxswCHgb6ezg+pQJS4cKyhGGHDtIz+n//k2rphQslER48CN9+K7csRYtCjRoyVlyypMwrLl9expHDw6VxxfHjcOJEIZYtg/j407fjx6U5yO7dsGMHbNki958tPFzeHERHQ5s2cjlcG2Io5X4mt6k+xpjGwHJrbUS2+/oBLa21t+f0cxEREfaaAO4fFxsbS8mSJZ0OwyMC+dhYu5a0tDQKXXWV05HkyFpZ+ScuTpJmQgKkpEBamis/vTbzY6NctwwJgYgISerFi8ul8MhI3xx7PsUPnr+CCuT/v0A+NoAlS5assda69MfpSvJtAXxlra2Q7b7HgQettdFnbdsd6J755RXAn3mI29+UAQK1q28gHxvo8fk7PT7/FcjHBlDbWuvSQu+uXFBKAM6eE1QcOOeilbV2PDAewBjzm6vvAPxRIB9fIB8b6PH5Oz0+/xXIxwZyfK5u60q18yagkDGmVrb7GgJabKWUUkrlQ67J11p7ApgBvGGMKWqMaQ7cAXzu6eCUUkqpQORqE7gngXDgIDAF6OnCNKPxBQnMDwTy8QXysYEen7/T4/NfgXxskIfjy7XgSimllFLu5ect3pVSSin/o8lXKaWU8jKvJF9jTC1jTLIxZrI39uctxpjJxph9xpg4Y8wmY0w3p2NyF2NMYWPMJ5m9vOONMWuNMbc4HZc7GWOeNsb8ZoxJMcZMcDqeggrkHuyB9lydLdD/3wL5tTK7vOQ6b535jgZ+9dK+vOktoLq1tjjQARhkjGnicEzuUgjYBbQESgADgenGmOoOxuRue4FBwKdOB+Im2XuwPwiMNcbUczYktwm05+psgf7/Fsivldm5nOs8nnyNMfcBscAiT+/L26y1f1lrU7K+zLzVdDAkt7HWnrDWvmat3W6tzbDWzga2AQHzD2OtnWGtnQkccTqWgsrWg/1la22CtXYZkNWD3e8F0nN1PoH+/xbIr5VZ8prrPJp8jTHFgTeAvp7cj5OMMWOMMYnAP8A+4AeHQ/IIY0x5IAptruKrooA0a+2mbPetAwLlzDeoBOL/WyC/VuYn13n6zPe/wCfW2t0e3o9jrLVPApFAC6QZScqFf8L/GGPCgC+Aidbaf3LbXjmiGBB31n3Hkb9N5UcC9f8twF8r85zr8p18jTExxhibw22ZMaYR0Bp4L7/7cFJux5d9W2tteuZlvipAT2cizhtXj88YE4J0MzsJPO1YwHmUl+cvQLjcg135Ln/9f3OVP75W5ia/uS7fK3WevaLReQLqDVQHdhpZo6wYEGqMqWutvTK/+/WW3I4vB4Xwk3EMV47PyBP3CVLAc6u1NtXTcblLPp8/f3aqB7u19t/M+7QHux/x5/+3fPCb10oXRJOPXOfJy87jkV9uo8zbh8AcoK0H9+k1xphyxpj7jDHFjDGhxpi2wP0EVmHZWOBy4HZrbZLTwbibMaaQMaYIEIr8sxQxxvjl0vGB3oM9kJ6rCwjI/7cgeK3MV67zWPK11iZaa/dn3ZDLYsnW2kOe2qeXWeSyyW7gGPAO0NtaO8vRqNzEGHMJ0AP5Y9pvjEnIvD3ocGjuNBBIAvoDD2V+PtDRiAomPz3Y/UWgPVdnCPD/t4B+rcxvrtPezkoppZSXaXtJpZRSyss0+SqllFJepslXKaWU8jJNvkoppZSXafJVSimlvEyTr1JKKeVlmnyVUkopL9Pkq5RSSnmZJl+llFLKyzT5KhUAjDHP57CC0xtOx6aUOpe2l1QqABhjIoGi2e7qBzwItLDWbnYmKqVUTjT5KhVgjDEvAM8Aray1G52ORyl1rkBbkkupoGaMGQA8Bdxord3kdDxKqfPT5KtUgDDGDASeAKL1UrNSvk2Tr1IBwBjzCtANaGmt3eJ0PEqpC9Pkq5SfyzzjfQboAJwwxlTI/FastTbZuciUUjnRgiul/JgxxgCxQPHzfLu1tXaRl0NSSrlAk69SSinlZdpkQymllPIyTb5KKaWUl2nyVUoppbxMk69SSinlZZp8lVJKKS/T5KuUUkp5mSZfpZRSyss0+SqllFJepslXKaWU8rL/BzJNtiuZCyhkAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x252 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 3.5))\n",
    "z = np.linspace(-4, 4, 200)\n",
    "plt.plot(z, huber_fn(0, z), \"b-\", linewidth=2, label=\"huber($z$)\")\n",
    "plt.plot(z, z**2 / 2, \"b:\", linewidth=1, label=r\"$\\frac{1}{2}z^2$\")\n",
    "plt.plot([-1, -1], [0, huber_fn(0., -1.)], \"r--\")\n",
    "plt.plot([1, 1], [0, huber_fn(0., 1.)], \"r--\")\n",
    "plt.gca().axhline(y=0, color='k')\n",
    "plt.gca().axvline(x=0, color='k')\n",
    "plt.axis([-4, 4, 0, 4])\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"$z$\")\n",
    "plt.legend(fontsize=14)\n",
    "plt.title(\"Huber loss\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to compile model with custom made loss\n",
    "model.compile(loss=huber_fn, optimizer=\"nadam\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/2\n",
      "11610/11610 [==============================] - 1s 71us/sample - loss: 0.6223 - mae: 0.9741 - val_loss: 0.2200 - val_mae: 0.5236\n",
      "Epoch 2/2\n",
      "11610/11610 [==============================] - 1s 48us/sample - loss: 0.2160 - mae: 0.5158 - val_loss: 0.2038 - val_mae: 0.4928\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x12e4aaac8>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving/Loading Models with Custom Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_a_custom_loss.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you load a model containing custom objects, you need to map the names to the objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_model_with_a_custom_loss.h5\",\n",
    "                                custom_objects={\"huber_fn\": huber_fn})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/2\n",
      "11610/11610 [==============================] - 1s 72us/sample - loss: 0.2056 - mae: 0.4990 - val_loss: 0.1890 - val_mae: 0.4743\n",
      "Epoch 2/2\n",
      "11610/11610 [==============================] - 1s 48us/sample - loss: 0.2004 - mae: 0.4911 - val_loss: 0.1876 - val_mae: 0.4724\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1384e1908>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_huber(threshold=1.0):\n",
    "    def huber_fn(y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < threshold\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss  = threshold * tf.abs(error) - threshold**2 / 2\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "    return huber_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=create_huber(2.0), optimizer=\"nadam\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/2\n",
      "11610/11610 [==============================] - 1s 73us/sample - loss: 0.2212 - mae: 0.4882 - val_loss: 0.2103 - val_mae: 0.4669\n",
      "Epoch 2/2\n",
      "11610/11610 [==============================] - 1s 49us/sample - loss: 0.2174 - mae: 0.4836 - val_loss: 0.2020 - val_mae: 0.4647\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x138432208>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_a_custom_loss_threshold_2.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, when you save the model, the threshold will not be saved. This means that you will have to specify the threshold value when loading the model (note that the name to use is \"`huber_fn`\", which is the name of the function you gave Keras, not the name of the function that created it). Note that the Keras API currently only specifies how to use subclassing to define layers, models, callbacks, and regularizers. If you build other components (such as losses, metrics, initializers, or constraints) using subclassing, they may not be portable to other Keras implementations. It’s likely that the Keras API will be updated to specify subclassing for all these components as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_model_with_a_custom_loss_threshold_2.h5\",\n",
    "                                custom_objects={\"huber_fn\": create_huber(2.0)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/2\n",
      "11610/11610 [==============================] - 1s 74us/sample - loss: 0.2141 - mae: 0.4789 - val_loss: 0.1983 - val_mae: 0.4616\n",
      "Epoch 2/2\n",
      "11610/11610 [==============================] - 1s 49us/sample - loss: 0.2112 - mae: 0.4767 - val_loss: 0.2140 - val_mae: 0.4645\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x139320978>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can solve this by creating a subclass of the `keras.losses.Los`s class, and then implementing its get_config() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuberLoss(keras.losses.Loss):\n",
    "    def __init__(self, threshold=1.0, **kwargs):\n",
    "        self.threshold = threshold\n",
    "        super().__init__(**kwargs)\n",
    "    def call(self, y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < self.threshold\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss  = self.threshold * tf.abs(error) - self.threshold**2 / 2\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"threshold\": self.threshold}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The constructor accepts `**kwargs` and passes them to the parent constructor, which handles standard hyperparameters: the `name` of the loss and the `reduction` algorithm to use to aggregate the individual instance losses. By default, it is \"sum_over_batch_size\", which means that the loss will be the sum of the instance losses, weighted by the sample weights, if any, and divided by the batch size (not by the sum of weights, so this is not the weighted mean).5 Other possible values are `\"sum\"` and None.\n",
    "\n",
    "The `call()` method takes the labels and predictions, computes all the instance losses, and returns them, i.e. the actual loss function.\n",
    "\n",
    "The `get_config()` method returns a dictionary mapping each hyperparameter name to its value. It first calls the parent class’s get_config() method (so you know it is an existing method in the base class), then adds the new hyperparameters to this dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=HuberLoss(2.), optimizer=\"nadam\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/2\n",
      "11610/11610 [==============================] - 1s 75us/sample - loss: 0.8046 - mae: 0.9679 - val_loss: 0.4891 - val_mae: 0.6449\n",
      "Epoch 2/2\n",
      "11610/11610 [==============================] - 1s 50us/sample - loss: 0.2531 - mae: 0.5239 - val_loss: 0.4233 - val_mae: 0.5946\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13aa2b240>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_a_custom_loss_class.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = keras.models.load_model(\"my_model_with_a_custom_loss_class.h5\", # TODO: check PR #25956\n",
    "#                                custom_objects={\"HuberLoss\": HuberLoss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/2\n",
      "11610/11610 [==============================] - 1s 49us/sample - loss: 0.2399 - mae: 0.5080 - val_loss: 0.3400 - val_mae: 0.5462\n",
      "Epoch 2/2\n",
      "11610/11610 [==============================] - 1s 50us/sample - loss: 0.2300 - mae: 0.4977 - val_loss: 0.2762 - val_mae: 0.5069\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13b4d6080>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = keras.models.load_model(\"my_model_with_a_custom_loss_class.h5\",  # TODO: check PR #25956\n",
    "#                                custom_objects={\"HuberLoss\": HuberLoss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-89c48d8ab0b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m \u001b[0;31m# Now you have the newly added attribute threshold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.loss.threshold # Now you have the newly added attribute threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Custom Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_softplus(z): # return value is just tf.nn.softplus(z)\n",
    "    return tf.math.log(tf.exp(z) + 1.0)\n",
    "\n",
    "def my_glorot_initializer(shape, dtype=tf.float32):\n",
    "    stddev = tf.sqrt(2. / (shape[0] + shape[1]))\n",
    "    return tf.random.normal(shape, stddev=stddev, dtype=dtype)\n",
    "\n",
    "def my_l1_regularizer(weights):\n",
    "    return tf.reduce_sum(tf.abs(0.01 * weights))\n",
    "\n",
    "def my_positive_weights(weights): # return value is just tf.nn.relu(weights)\n",
    "    return tf.where(weights < 0., tf.zeros_like(weights), weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = keras.layers.Dense(1, activation=my_softplus,\n",
    "                           kernel_initializer=my_glorot_initializer,\n",
    "                           kernel_regularizer=my_l1_regularizer,\n",
    "                           kernel_constraint=my_positive_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1, activation=my_softplus,\n",
    "                       kernel_regularizer=my_l1_regularizer,\n",
    "                       kernel_constraint=my_positive_weights,\n",
    "                       kernel_initializer=my_glorot_initializer),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/2\n",
      "11610/11610 [==============================] - 1s 77us/sample - loss: 1.9031 - mae: 0.8792 - val_loss: inf - val_mae: inf\n",
      "Epoch 2/2\n",
      "11610/11610 [==============================] - 1s 49us/sample - loss: 0.7626 - mae: 0.5320 - val_loss: inf - val_mae: inf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x138432128>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_many_custom_parts.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmodel = keras.models.load_model(\\n    \"my_model_with_many_custom_parts.h5\",\\n    custom_objects={\\n       \"my_l1_regularizer\": my_l1_regularizer(0.01),\\n       \"my_positive_weights\": my_positive_weights,\\n       \"my_glorot_initializer\": my_glorot_initializer,\\n       \"my_softplus\": my_softplus,\\n    })\\n'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: \n",
    "\"\"\"\n",
    "model = keras.models.load_model(\n",
    "    \"my_model_with_many_custom_parts.h5\",\n",
    "    custom_objects={\n",
    "       \"my_l1_regularizer\": my_l1_regularizer(0.01),\n",
    "       \"my_positive_weights\": my_positive_weights,\n",
    "       \"my_glorot_initializer\": my_glorot_initializer,\n",
    "       \"my_softplus\": my_softplus,\n",
    "    })\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a function has hyperparameters that need to be saved along with the model, then you will want to subclass the appropriate class, such as `keras.regularizers.Regularizer`, `keras.constraints.Constraint`, `keras.initializers.Initializer`, or `keras.layers.Layer` (for any layer, including activation functions). Much like we did for the custom loss. Note that you must implement the `call()` method for losses, layers (including activation functions), and models, or the `__call__()` method for regularizers, initializers, and constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyL1Regularizer(keras.regularizers.Regularizer):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "    def __call__(self, weights):\n",
    "        return tf.reduce_sum(tf.abs(self.factor * weights))\n",
    "    def get_config(self):\n",
    "        return {\"factor\": self.factor}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1, activation=my_softplus,\n",
    "                       kernel_regularizer=MyL1Regularizer(0.01),\n",
    "                       kernel_constraint=my_positive_weights,\n",
    "                       kernel_initializer=my_glorot_initializer),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/2\n",
      "11610/11610 [==============================] - 1s 75us/sample - loss: 2.3877 - mae: 0.9873 - val_loss: inf - val_mae: inf\n",
      "Epoch 2/2\n",
      "11610/11610 [==============================] - 1s 49us/sample - loss: 0.9491 - mae: 0.5495 - val_loss: inf - val_mae: inf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13be91278>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_many_custom_parts.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmodel = keras.models.load_model(\\n    \"my_model_with_many_custom_parts.h5\",\\n    custom_objects={\\n       \"MyL1Regularizer\": MyL1Regularizer,\\n       \"my_positive_weights\": my_positive_weights,\\n       \"my_glorot_initializer\": my_glorot_initializer,\\n       \"my_softplus\": my_softplus,\\n    })\\n'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: check https://github.com/tensorflow/tensorflow/issues/26061\n",
    "\"\"\"\n",
    "model = keras.models.load_model(\n",
    "    \"my_model_with_many_custom_parts.h5\",\n",
    "    custom_objects={\n",
    "       \"MyL1Regularizer\": MyL1Regularizer,\n",
    "       \"my_positive_weights\": my_positive_weights,\n",
    "       \"my_glorot_initializer\": my_glorot_initializer,\n",
    "       \"my_softplus\": my_softplus,\n",
    "    })\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Metrics\n",
    "\n",
    "In most cases, defining a custom metric function is exactly the same as defining a custom loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\", metrics=[create_huber(2.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "11610/11610 [==============================] - 1s 56us/sample - loss: 2.0490 - huber_fn: 0.8245\n",
      "Epoch 2/2\n",
      "11610/11610 [==============================] - 0s 35us/sample - loss: 0.6203 - huber_fn: 0.2507\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13ca48dd8>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning**: if you use the same function as the loss and a metric, you may be surprised to see different results. This is generally just due to floating point precision errors: even though the mathematical equations are equivalent, the operations are not run in the same order, which can lead to small differences. Moreover, when using sample weights, there's more than just precision errors:\n",
    "* the loss since the start of the epoch is the mean of all batch losses seen so far. Each batch loss is the sum of the weighted instance losses divided by the _batch size_ (not the sum of weights, so the batch loss is _not_ the weighted mean of the losses).\n",
    "* the metric since the start of the epoch is equal to the sum of weighted instance losses divided by sum of all weights seen so far. In other words, it is the weighted mean of all the instance losses. Not the same thing.\n",
    "\n",
    "If you do the math, you will find that metric = loss * mean of sample weights (plus some floating point precision error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=create_huber(2.0), optimizer=\"nadam\", metrics=[create_huber(2.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "11610/11610 [==============================] - 1s 60us/sample - loss: 0.1167 - huber_fn: 0.2309\n",
      "Epoch 2/2\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.1115 - huber_fn: 0.2218\n"
     ]
    }
   ],
   "source": [
    "sample_weight = np.random.rand(len(y_train))\n",
    "history = model.fit(X_train_scaled, y_train, epochs=2, sample_weight=sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.11666121805001702, 0.11494729649264307)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history[\"loss\"][0], history.history[\"huber_fn\"][0] * sample_weight.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming metrics\n",
    "\n",
    "Streaming metric, or stateful metric, gradually updated, batch after batch. For instance, the precision metric used below computes and keeps track of the most up-to-date precision among all batches, not just the current or latest batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=84595, shape=(), dtype=float32, numpy=0.8>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = keras.metrics.Precision()\n",
    "precision([0, 1, 1, 1, 0, 1, 0, 1], [1, 1, 0, 1, 0, 1, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=84645, shape=(), dtype=float32, numpy=0.5>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision([0, 1, 0, 0, 1, 0, 1, 1], [1, 0, 1, 1, 0, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=84655, shape=(), dtype=float32, numpy=0.5>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision.result() # to get the current value of the metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'true_positives:0' shape=(1,) dtype=float32, numpy=array([4.], dtype=float32)>,\n",
       " <tf.Variable 'false_positives:0' shape=(1,) dtype=float32, numpy=array([4.], dtype=float32)>]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision.variables # tracking the number of true and false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision.reset_states() # reset the state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a customized streaming metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuberMetric(keras.metrics.Metric):\n",
    "    def __init__(self, threshold=1.0, **kwargs):\n",
    "        super().__init__(**kwargs) # handles base args (e.g., dtype)\n",
    "        self.threshold = threshold\n",
    "        self.huber_fn = create_huber(threshold)\n",
    "        self.total = self.add_weight(\"total\", initializer=\"zeros\")\n",
    "        self.count = self.add_weight(\"count\", initializer=\"zeros\")\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        metric = self.huber_fn(y_true, y_pred)\n",
    "        self.total.assign_add(tf.reduce_sum(metric))\n",
    "        self.count.assign_add(tf.cast(tf.size(y_true), tf.float32))\n",
    "    def result(self):\n",
    "        return self.total / self.count\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"threshold\": self.threshold}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's walk through the code above.\n",
    "\n",
    "- The constructor uses the `add_weight()` method to create the `tf.Variables` needed to keep track of the metric’s state over multiple batches—in this case, the sum of all Huber losses (total) and the number of instances seen so far (count). You could just create `tf.Variable` manually if you preferred. **Keras tracks any tf.Variable that is set as an attribute (and more generally, any “trackable” object, such as layers or models)**.\n",
    "\n",
    "- The `update_state()` method is called when you use an instance of this class as a function (as we did with the Precision object). It updates the variables, given the labels and predictions for one batch (and sample weights, but in this case we ignore them).\n",
    "\n",
    "- The `result()` method computes and returns the final result, in this case the mean Huber metric over all instances. When you use the metric as a function, the `update_state()` method gets called first, then the `result()` method is called, and its output is returned.\n",
    "\n",
    "- We also implement the `get_config()` method to ensure the threshold gets saved along with the model.\n",
    "\n",
    "- The default implementation of the `reset_states()` method resets all variables to 0.0 (but you can override it if needed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=84709, shape=(), dtype=float32, numpy=14.0>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = HuberMetric(2.)\n",
    "\n",
    "# total = 2 * |10 - 2| - 2²/2 = 14\n",
    "# count = 1\n",
    "# result = 14 / 1 = 14\n",
    "m(tf.constant([[2.]]), tf.constant([[10.]])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=84745, shape=(), dtype=float32, numpy=7.0>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total = total + (|1 - 0|² / 2) + (2 * |9.25 - 5| - 2² / 2) = 14 + 7 = 21\n",
    "# count = count + 2 = 3\n",
    "# result = total / count = 21 / 3 = 7\n",
    "m(tf.constant([[0.], [5.]]), tf.constant([[1.], [9.25]]))\n",
    "\n",
    "m.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'total:0' shape=() dtype=float32, numpy=21.0>,\n",
       " <tf.Variable 'count:0' shape=() dtype=float32, numpy=3.0>]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'total:0' shape=() dtype=float32, numpy=0.0>,\n",
       " <tf.Variable 'count:0' shape=() dtype=float32, numpy=0.0>]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.reset_states()\n",
    "m.variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that the `HuberMetric` class works well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=create_huber(2.0), optimizer=\"nadam\", metrics=[HuberMetric(2.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "11610/11610 [==============================] - 1s 63us/sample - loss: 0.8135 - huber_metric_1: 0.8135\n",
      "Epoch 2/2\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.2471 - huber_metric_1: 0.2471\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13e15b7f0>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_a_custom_metric.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = keras.models.load_model(\"my_model_with_a_custom_metric.h5\",           # TODO: check PR #25956\n",
    "#                                custom_objects={\"huber_fn\": create_huber(2.0),\n",
    "#                                                \"HuberMetric\": HuberMetric})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.2324 - huber_metric_1: 0.2324\n",
      "Epoch 2/2\n",
      "11610/11610 [==============================] - 0s 38us/sample - loss: 0.2236 - huber_metric_1: 0.2236\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13b683ac8>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics[0].threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like it works fine! More simply, we could have created the class like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuberMetric(keras.metrics.Mean):\n",
    "    def __init__(self, threshold=1.0, name='HuberMetric', dtype=None):\n",
    "        self.threshold = threshold\n",
    "        self.huber_fn = create_huber(threshold)\n",
    "        super().__init__(name=name, dtype=dtype)\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        metric = self.huber_fn(y_true, y_pred)\n",
    "        super(HuberMetric, self).update_state(metric, sample_weight)\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"threshold\": self.threshold}        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class handles shapes better, and it also supports sample weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.Huber(2.0), optimizer=\"nadam\", weighted_metrics=[HuberMetric(2.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "11610/11610 [==============================] - 1s 84us/sample - loss: 0.4076 - HuberMetric: 0.8146\n",
      "Epoch 2/2\n",
      "11610/11610 [==============================] - 1s 52us/sample - loss: 0.1188 - HuberMetric: 0.2374\n"
     ]
    }
   ],
   "source": [
    "sample_weight = np.random.rand(len(y_train))\n",
    "history = model.fit(X_train_scaled, y_train, epochs=2, sample_weight=sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.407584022901933, 0.4075840845370592)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history[\"loss\"][0], history.history[\"HuberMetric\"][0] * sample_weight.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_a_custom_metric_v2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = keras.models.load_model(\"my_model_with_a_custom_metric_v2.h5\",        # TODO: check PR #25956\n",
    "#                                custom_objects={\"HuberMetric\": HuberMetric})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.2269 - HuberMetric: 0.2269\n",
      "Epoch 2/2\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.2193 - HuberMetric: 0.2193\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13f1e97b8>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics[0].threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "exponential_layer = keras.layers.Lambda(lambda x: tf.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=110600, shape=(3,), dtype=float32, numpy=array([0.36787945, 1.        , 2.7182817 ], dtype=float32)>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exponential_layer([-1., 0., 1.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding an exponential layer at the output of a regression model can be useful if the values to predict are positive and with very different scales (e.g., 0.001, 10., 10000):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/5\n",
      "11610/11610 [==============================] - 1s 81us/sample - loss: 17455295763.6862 - val_loss: 5.2690\n",
      "Epoch 2/5\n",
      "11610/11610 [==============================] - 1s 50us/sample - loss: 34.5006 - val_loss: 1.6420\n",
      "Epoch 3/5\n",
      "11610/11610 [==============================] - 1s 50us/sample - loss: 2.1489 - val_loss: 1.1421\n",
      "Epoch 4/5\n",
      "11610/11610 [==============================] - 1s 49us/sample - loss: 1.1264 - val_loss: 0.7558\n",
      "Epoch 5/5\n",
      "11610/11610 [==============================] - 1s 48us/sample - loss: 0.6549 - val_loss: 0.6205\n",
      "5160/5160 [==============================] - 0s 19us/sample - loss: 29118.6526\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "29118.652586295255"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "    exponential_layer\n",
    "])\n",
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "model.fit(X_train_scaled, y_train, epochs=5,\n",
    "          validation_data=(X_valid_scaled, y_valid))\n",
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDense(keras.layers.Layer):\n",
    "    def __init__(self, units, activation=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.activation = keras.activations.get(activation)\n",
    "\n",
    "    def build(self, batch_input_shape):\n",
    "        self.kernel = self.add_weight(\n",
    "            name=\"kernel\", shape=[batch_input_shape[-1], self.units],\n",
    "            initializer=\"glorot_normal\")\n",
    "        self.bias = self.add_weight(\n",
    "            name=\"bias\", shape=[self.units], initializer=\"zeros\")\n",
    "        super().build(batch_input_shape) # must be at the end\n",
    "\n",
    "    def call(self, X):\n",
    "        return self.activation(X @ self.kernel + self.bias)\n",
    "\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return tf.TensorShape(batch_input_shape.as_list()[:-1] + [self.units])\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"units\": self.units,\n",
    "                \"activation\": keras.activations.serialize(self.activation)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s walk through this code:\n",
    "\n",
    " - The constructor takes all the hyperparameters as arguments (in this example, units and activation), and importantly it also takes a `**kwargs` argument. It calls the parent constructor, passing it the kwargs: this takes care of standard arguments such as `input_shape`, `trainable`, and `name`. Then it saves the hyperparameters as attributes, converting the activation argument to the appropriate activation function using the `keras.activations.get()` function (it accepts functions, standard strings like \"relu\" or \"selu\", or simply None).\n",
    "\n",
    " - The `build()` method’s role is to create the layer’s variables by calling the `add_weight()` method for each weight. The `build()` method is called the first time the layer is used. At that point, Keras will know the shape of this layer’s inputs, and it will pass it to the build() method,9 which is often necessary to create some of the weights. For example, we need to know the number of neurons in the previous layer in order to create the connection weights matrix (i.e., the \"kernel\"): this corresponds to the size of the last dimension of the inputs. **At the end of the `build()` method (and only at the end), you must call the parent’s `build()` method**: this tells Keras that the layer is built (it just sets self.built=True).\n",
    "\n",
    " - The `call()` method performs the desired operations. In this case, we compute the matrix multiplication of the inputs `X` and the layer’s kernel, we add the bias vector, and we apply the activation function to the result, and this gives us the output of the layer.\n",
    "\n",
    " - The `compute_output_shape()` method simply returns the shape of this layer’s outputs. In this case, it is the same shape as the inputs, except the last dimension is replaced with the number of neurons in the layer. Note that in `tf.keras`, shapes are instances of the `tf.TensorShape` class, which you can convert to Python lists using `as_list()`. You can generally omit the `compute_output_shape()` method, as `tf.keras` automatically infers the output shape, except when the layer is dynamic. In other Keras implementations, this method is either required or its default implementation assumes the output shape is the same as the input shape.\n",
    "\n",
    " - The `get_config()` method is just like in the previous custom classes. Note that we save the activation function’s full configuration by calling `keras.activations.serialize()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    MyDense(30, activation=\"relu\", input_shape=input_shape),\n",
    "    MyDense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/2\n",
      "11610/11610 [==============================] - 1s 70us/sample - loss: 1.4813 - val_loss: 22.7766\n",
      "Epoch 2/2\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.7190 - val_loss: 15.0291\n",
      "5160/5160 [==============================] - 0s 18us/sample - loss: 0.5322\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5321827204652535"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))\n",
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_a_custom_layer.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_model_with_a_custom_layer.h5\",\n",
    "                                custom_objects={\"MyDense\": MyDense})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMultiLayer(keras.layers.Layer):\n",
    "    def call(self, X):\n",
    "        X1, X2 = X\n",
    "        return X1 + X2, X1 * X2\n",
    "\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        batch_input_shape1, batch_input_shape2 = batch_input_shape\n",
    "        return [batch_input_shape1, batch_input_shape2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This layer may now be used like any other layer, but of course only using the Functional and Subclassing APIs, not the Sequential API (which only accepts layers with one input and one output)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs1 = keras.layers.Input(shape=[2])\n",
    "inputs2 = keras.layers.Input(shape=[2])\n",
    "outputs1, outputs2 = MyMultiLayer()((inputs1, inputs2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a layer with a different behavior during training and testing. It is done by adding a `training` argument to the `call` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddGaussianNoise(keras.layers.Layer):\n",
    "    def __init__(self, stddev, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.stddev = stddev\n",
    "\n",
    "    def call(self, X, training=None):\n",
    "        if training:\n",
    "            noise = tf.random.normal(tf.shape(X), stddev=self.stddev)\n",
    "            return X + noise\n",
    "        else:\n",
    "            return X\n",
    "\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return batch_input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/2\n",
      "11610/11610 [==============================] - 1s 70us/sample - loss: 0.5817 - val_loss: 12.9048\n",
      "Epoch 2/2\n",
      "11610/11610 [==============================] - 1s 48us/sample - loss: 0.5087 - val_loss: 8.0876\n",
      "5160/5160 [==============================] - 0s 17us/sample - loss: 0.4285\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4284568049648935"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))\n",
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new_scaled = X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(keras.layers.Layer):\n",
    "    def __init__(self, n_layers, n_neurons, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.n_layers = n_layers                                     # not shown in the book\n",
    "        self.n_neurons = n_neurons                                   # not shown\n",
    "        self.hidden = [keras.layers.Dense(n_neurons, activation=\"elu\",\n",
    "                                          kernel_initializer=\"he_normal\")\n",
    "                       for _ in range(n_layers)]\n",
    "\n",
    "    def call(self, inputs):\n",
    "        Z = inputs\n",
    "        for layer in self.hidden:\n",
    "            Z = layer(Z)\n",
    "        return inputs + Z\n",
    "    \n",
    "    def get_config(self):                                            # not shown\n",
    "        base_config = super().get_config()                           # not shown\n",
    "        return {**base_config,                                       # not shown\n",
    "                \"n_layers\": self.n_layers, \"n_neurons\": n_neurons}   # not shown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above layer is a bit special since it contains other layers. This is handled transparently by Keras: it automatically detects that the hidden attribute contains trackable objects (layers in this case), so their variables are automatically added to this layer’s list of variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualRegressor(keras.models.Model):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.output_dim = output_dim                                 # not shown in the book\n",
    "        self.hidden1 = keras.layers.Dense(30, activation=\"elu\",\n",
    "                                          kernel_initializer=\"he_normal\")\n",
    "        self.block1 = ResidualBlock(2, 30)\n",
    "        self.block2 = ResidualBlock(2, 30)\n",
    "        self.out = keras.layers.Dense(output_dim)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        Z = self.hidden1(inputs)\n",
    "        for _ in range(1 + 3):\n",
    "            Z = self.block1(Z)\n",
    "        Z = self.block2(Z)\n",
    "        return self.out(Z)\n",
    "\n",
    "    def get_config(self):                                            # not shown\n",
    "        base_config = super().get_config()                           # not shown\n",
    "        return {**base_config,                                       # not shown\n",
    "                \"output_dim\": self.output_dim}                       # not shown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you also want to be able to save the model using the `save()` method and load it using the `keras.models.load_model()` function, you must implement the `get_config()` method (as we did earlier) in both the `ResidualBlock` class and the `ResidualRegressor` class. Alternatively, you can save and load the weights using the `save_weights()` and `load_weights()` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "11610/11610 [==============================] - 1s 118us/sample - loss: 2.7279\n",
      "Epoch 2/5\n",
      "11610/11610 [==============================] - 1s 69us/sample - loss: 1.0324\n",
      "Epoch 3/5\n",
      "11610/11610 [==============================] - 1s 66us/sample - loss: 1.0542\n",
      "Epoch 4/5\n",
      "11610/11610 [==============================] - 1s 64us/sample - loss: 0.5402\n",
      "Epoch 5/5\n",
      "11610/11610 [==============================] - 1s 65us/sample - loss: 0.6903\n",
      "5160/5160 [==============================] - 0s 34us/sample - loss: 1.2116\n"
     ]
    }
   ],
   "source": [
    "model = ResidualRegressor(1)\n",
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "history = model.fit(X_train_scaled, y_train, epochs=5)\n",
    "score = model.evaluate(X_test_scaled, y_test)\n",
    "y_pred = model.predict(X_new_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: check that persistence ends up working in TF2\n",
    "#model.save(\"my_custom_model.h5\")\n",
    "#model = keras.models.load_model(\"my_custom_model.h5\",\n",
    "#                                custom_objects={\n",
    "#                                    \"ResidualBlock\": ResidualBlock,\n",
    "#                                    \"ResidualRegressor\": ResidualRegressor\n",
    "#                                })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could have defined the model using the sequential API instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "block1 = ResidualBlock(2, 30)\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    block1, block1, block1, block1,\n",
    "    ResidualBlock(2, 30),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "11610/11610 [==============================] - 2s 163us/sample - loss: 1.5833\n",
      "Epoch 2/5\n",
      "11610/11610 [==============================] - 1s 97us/sample - loss: 0.6670\n",
      "Epoch 3/5\n",
      "11610/11610 [==============================] - 1s 96us/sample - loss: 2.2517\n",
      "Epoch 4/5\n",
      "11610/11610 [==============================] - 1s 94us/sample - loss: 0.5019\n",
      "Epoch 5/5\n",
      "11610/11610 [==============================] - 1s 94us/sample - loss: 0.5117\n",
      "5160/5160 [==============================] - 0s 28us/sample - loss: 1.0046\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "history = model.fit(X_train_scaled, y_train, epochs=5)\n",
    "score = model.evaluate(X_test_scaled, y_test)\n",
    "y_pred = model.predict(X_new_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Losses and Metrics Based on Model Internals\n",
    "\n",
    "The custom losses and metrics we defined earlier were all based on the labels and the predictions (and optionally sample weights). There will be times when you want to define losses based on other parts of your model, such as the weights or activations of its hidden layers. This may be useful for regularization purposes or to monitor some internal aspect of your model.\n",
    "\n",
    "To define a custom loss based on model internals, compute it based on any part of the model you want, then pass the result to the `add_loss()` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: check https://github.com/tensorflow/tensorflow/issues/26260\n",
    "```python\n",
    "class ReconstructingRegressor(keras.models.Model):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden = [keras.layers.Dense(30, activation=\"selu\",\n",
    "                                          kernel_initializer=\"lecun_normal\")\n",
    "                       for _ in range(5)]\n",
    "        self.out = keras.layers.Dense(output_dim)\n",
    "        self.reconstruction_mean = keras.metrics.Mean(name=\"reconstruction_error\")\n",
    "\n",
    "    def build(self, batch_input_shape):\n",
    "        n_inputs = batch_input_shape[-1]\n",
    "        self.reconstruct = keras.layers.Dense(n_inputs)\n",
    "        super().build(batch_input_shape)\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, inputs, training=None):\n",
    "        Z = inputs\n",
    "        for layer in self.hidden:\n",
    "            Z = layer(Z)\n",
    "        reconstruction = self.reconstruct(Z)\n",
    "        recon_loss = tf.reduce_mean(tf.square(reconstruction - inputs))\n",
    "        self.add_loss(0.05 * reconstruction_loss)\n",
    "        if training:\n",
    "            result = self.reconstruction_mean(recon_loss)\n",
    "            self.add_metric(result)\n",
    "        return self.out(Z)\n",
    "\n",
    "model = ReconstructingRegressor(1)\n",
    "model.build(tf.TensorShape([None, 8]))       # <= Fails if this line is removed\n",
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "history = model.fit(X, y, epochs=2)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s go through this code above:\n",
    "\n",
    " - The constructor creates the DNN with five dense hidden layers and one dense output layer.\n",
    "\n",
    " - The `build()` method creates an extra dense layer which will be used to reconstruct the inputs of the model. It must be created here because its number of units must be equal to the number of inputs, and this number is unknown before the `build()` method is called.\n",
    "\n",
    " - The `call()` method processes the inputs through all five hidden layers, then passes the result through the reconstruction layer, which produces the reconstruction.\n",
    "\n",
    " - Then the `call()` method computes the reconstruction loss (the mean squared difference between the reconstruction and the inputs), and adds it to the model’s list of losses using the `add_loss()` method.11 Notice that we scale down the reconstruction loss by multiplying it by 0.05 (this is a hyperparameter you can tune). This ensures that the reconstruction loss does not dominate the main loss.\n",
    "\n",
    " - Finally, the `call()` method passes the output of the hidden layers to the output layer and returns its output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, you can add a custom metric based on model internals by computing it in any way you want, as long as the result is the output of a metric object. For example, you can create a `keras.metrics.Mean` object in the constructor, then call it in the `call()` method, passing it the recon_loss, and finally add it to the model by calling the model’s `add_metric()` method. This way, when you train the model, Keras will display both the mean loss over each epoch (the loss is the sum of the main loss plus 0.05 times the reconstruction loss) and the mean reconstruction error over each epoch. Both will go down during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReconstructingRegressor(keras.models.Model):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden = [keras.layers.Dense(30, activation=\"selu\",\n",
    "                                          kernel_initializer=\"lecun_normal\")\n",
    "                       for _ in range(5)]\n",
    "        self.out = keras.layers.Dense(output_dim)\n",
    "\n",
    "    def build(self, batch_input_shape):\n",
    "        n_inputs = batch_input_shape[-1]\n",
    "        self.reconstruct = keras.layers.Dense(n_inputs)\n",
    "        super().build(batch_input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        Z = inputs\n",
    "        for layer in self.hidden:\n",
    "            Z = layer(Z)\n",
    "        reconstruction = self.reconstruct(Z)\n",
    "        recon_loss = tf.reduce_mean(tf.square(reconstruction - inputs))\n",
    "        self.add_loss(0.05 * recon_loss)\n",
    "        return self.out(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "11610/11610 [==============================] - 2s 141us/sample - loss: 0.6859\n",
      "Epoch 2/2\n",
      "11610/11610 [==============================] - 1s 83us/sample - loss: 0.4133\n"
     ]
    }
   ],
   "source": [
    "model = ReconstructingRegressor(1)\n",
    "model.build(tf.TensorShape([None, 8])) # TODO: check https://github.com/tensorflow/tensorflow/issues/26274\n",
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "history = model.fit(X_train_scaled, y_train, epochs=2)\n",
    "y_pred = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Up to this point, it is said that it should cover 99% of the use case. The below covers the case where the graph needs to be built dynamically, and hence did not read this portion of the book and the below.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Gradients Using Autodiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(w1, w2):\n",
    "    return 3 * w1 ** 2 + 2 * w1 * w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.000003007075065"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1, w2 = 5, 3\n",
    "eps = 1e-6\n",
    "(f(w1 + eps, w2) - f(w1, w2)) / eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.000000003174137"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(f(w1, w2 + eps) - f(w1, w2)) / eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1, w2 = tf.Variable(5.), tf.Variable(3.)\n",
    "with tf.GradientTape() as tape:\n",
    "    z = f(w1, w2)\n",
    "\n",
    "gradients = tape.gradient(z, [w1, w2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: id=180500, shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: id=180471, shape=(), dtype=float32, numpy=10.0>]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientTape.gradient can only be called once on non-persistent tapes.\n"
     ]
    }
   ],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    z = f(w1, w2)\n",
    "\n",
    "dz_dw1 = tape.gradient(z, w1)\n",
    "try:\n",
    "    dz_dw2 = tape.gradient(z, w2)\n",
    "except RuntimeError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    z = f(w1, w2)\n",
    "\n",
    "dz_dw1 = tape.gradient(z, w1)\n",
    "dz_dw2 = tape.gradient(z, w2) # works now!\n",
    "del tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=180588, shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: id=180591, shape=(), dtype=float32, numpy=10.0>)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dz_dw1, dz_dw2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1, c2 = tf.constant(5.), tf.constant(3.)\n",
    "with tf.GradientTape() as tape:\n",
    "    z = f(c1, c2)\n",
    "\n",
    "gradients = tape.gradient(z, [c1, c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(c1)\n",
    "    tape.watch(c2)\n",
    "    z = f(c1, c2)\n",
    "\n",
    "gradients = tape.gradient(z, [c1, c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: id=180671, shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: id=180642, shape=(), dtype=float32, numpy=10.0>]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: id=180806, shape=(), dtype=float32, numpy=136.0>,\n",
       " <tf.Tensor: id=180807, shape=(), dtype=float32, numpy=30.0>]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    z1 = f(w1, w2 + 2.)\n",
    "    z2 = f(w1, w2 + 5.)\n",
    "    z3 = f(w1, w2 + 7.)\n",
    "\n",
    "tape.gradient([z1, z2, z3], [w1, w2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    z1 = f(w1, w2 + 2.)\n",
    "    z2 = f(w1, w2 + 5.)\n",
    "    z3 = f(w1, w2 + 7.)\n",
    "\n",
    "tf.reduce_sum(tf.stack([tape.gradient(z, [w1, w2]) for z in (z1, z2, z3)]), axis=0)\n",
    "del tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape(persistent=True) as hessian_tape:\n",
    "    with tf.GradientTape() as jacobian_tape:\n",
    "        z = f(w1, w2)\n",
    "    jacobians = jacobian_tape.gradient(z, [w1, w2])\n",
    "hessians = [hessian_tape.gradient(jacobian, [w1, w2])\n",
    "            for jacobian in jacobians]\n",
    "del hessian_tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: id=180993, shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: id=180964, shape=(), dtype=float32, numpy=10.0>]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[<tf.Tensor: id=181017, shape=(), dtype=float32, numpy=6.0>,\n",
       "  <tf.Tensor: id=181034, shape=(), dtype=float32, numpy=2.0>],\n",
       " [<tf.Tensor: id=181039, shape=(), dtype=float32, numpy=2.0>, None]]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hessians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: id=181073, shape=(), dtype=float32, numpy=30.0>, None]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(w1, w2):\n",
    "    return 3 * w1 ** 2 + tf.stop_gradient(2 * w1 * w2)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    z = f(w1, w2)\n",
    "\n",
    "tape.gradient(z, [w1, w2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: id=181103, shape=(), dtype=float32, numpy=nan>]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.Variable(100.)\n",
    "with tf.GradientTape() as tape:\n",
    "    z = my_softplus(x)\n",
    "\n",
    "tape.gradient(z, [x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=181109, shape=(), dtype=float32, numpy=30.0>"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.log(tf.exp(tf.constant(30., dtype=tf.float32)) + 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: id=181136, shape=(1,), dtype=float32, numpy=array([nan], dtype=float32)>]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.Variable([100.])\n",
    "with tf.GradientTape() as tape:\n",
    "    z = my_softplus(x)\n",
    "\n",
    "tape.gradient(z, [x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.custom_gradient\n",
    "def my_better_softplus(z):\n",
    "    exp = tf.exp(z)\n",
    "    def my_softplus_gradients(grad):\n",
    "        return grad / (1 + 1 / exp)\n",
    "    return tf.math.log(exp + 1), my_softplus_gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_better_softplus(z):\n",
    "    return tf.where(z > 30., z, tf.math.log(tf.exp(z) + 1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=181154, shape=(1,), dtype=float32, numpy=array([1000.], dtype=float32)>,\n",
       " [<tf.Tensor: id=181178, shape=(1,), dtype=float32, numpy=array([nan], dtype=float32)>])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.Variable([1000.])\n",
    "with tf.GradientTape() as tape:\n",
    "    z = my_better_softplus(x)\n",
    "\n",
    "z, tape.gradient(z, [x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing Gradients Using Autodiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_reg = keras.regularizers.l2(0.05)\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"elu\", kernel_initializer=\"he_normal\",\n",
    "                       kernel_regularizer=l2_reg),\n",
    "    keras.layers.Dense(1, kernel_regularizer=l2_reg)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_batch(X, y, batch_size=32):\n",
    "    idx = np.random.randint(len(X), size=batch_size)\n",
    "    return X[idx], y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_status_bar(iteration, total, loss, metrics=None):\n",
    "    metrics = \" - \".join([\"{}: {:.4f}\".format(m.name, m.result())\n",
    "                         for m in [loss] + (metrics or [])])\n",
    "    end = \"\" if iteration < total else \"\\n\"\n",
    "    print(\"\\r{}/{} - \".format(iteration, total) + metrics,\n",
    "          end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 - loss: 0.0900 - mean_square: 858.5000\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "mean_loss = keras.metrics.Mean(name=\"loss\")\n",
    "mean_square = keras.metrics.Mean(name=\"mean_square\")\n",
    "for i in range(1, 50 + 1):\n",
    "    loss = 1 / i\n",
    "    mean_loss(loss)\n",
    "    mean_square(i ** 2)\n",
    "    print_status_bar(i, 50, mean_loss, [mean_square])\n",
    "    time.sleep(0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A fancier version with a progress bar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def progress_bar(iteration, total, size=30):\n",
    "    running = iteration < total\n",
    "    c = \">\" if running else \"=\"\n",
    "    p = (size - 1) * iteration // total\n",
    "    fmt = \"{{:-{}d}}/{{}} [{{}}]\".format(len(str(total)))\n",
    "    params = [iteration, total, \"=\" * p + c + \".\" * (size - p - 1)]\n",
    "    return fmt.format(*params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 3500/10000 [=>....]'"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "progress_bar(3500, 10000, size=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_status_bar(iteration, total, loss, metrics=None, size=30):\n",
    "    metrics = \" - \".join([\"{}: {:.4f}\".format(m.name, m.result())\n",
    "                         for m in [loss] + (metrics or [])])\n",
    "    end = \"\" if iteration < total else \"\\n\"\n",
    "    print(\"\\r{} - {}\".format(progress_bar(iteration, total), metrics), end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - loss: 0.0900 - mean_square: 858.5000\n"
     ]
    }
   ],
   "source": [
    "mean_loss = keras.metrics.Mean(name=\"loss\")\n",
    "mean_square = keras.metrics.Mean(name=\"mean_square\")\n",
    "for i in range(1, 50 + 1):\n",
    "    loss = 1 / i\n",
    "    mean_loss(loss)\n",
    "    mean_square(i ** 2)\n",
    "    print_status_bar(i, 50, mean_loss, [mean_square])\n",
    "    time.sleep(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "batch_size = 32\n",
    "n_steps = len(X_train) // batch_size\n",
    "optimizer = keras.optimizers.Nadam(lr=0.01)\n",
    "loss_fn = keras.losses.mean_squared_error\n",
    "mean_loss = keras.metrics.Mean()\n",
    "metrics = [keras.metrics.MeanAbsoluteError()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "11610/11610 [==============================] - mean: 1.5850 - mean_absolute_error: 0.57446\n",
      "Epoch 2/5\n",
      "11610/11610 [==============================] - mean: 0.7521 - mean_absolute_error: 0.5266\n",
      "Epoch 3/5\n",
      "11610/11610 [==============================] - mean: 0.7095 - mean_absolute_error: 0.5347\n",
      "Epoch 4/5\n",
      "11610/11610 [==============================] - mean: 0.6629 - mean_absolute_error: 0.5236\n",
      "Epoch 5/5\n",
      "11610/11610 [==============================] - mean: 0.6421 - mean_absolute_error: 0.5150\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs + 1):\n",
    "    print(\"Epoch {}/{}\".format(epoch, n_epochs))\n",
    "    for step in range(1, n_steps + 1):\n",
    "        X_batch, y_batch = random_batch(X_train_scaled, y_train)\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(X_batch)\n",
    "            main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "            loss = tf.add_n([main_loss] + model.losses)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        for variable in model.variables:\n",
    "            if variable.constraint is not None:\n",
    "                variable.assign(variable.constraint(variable))\n",
    "        mean_loss(loss)\n",
    "        for metric in metrics:\n",
    "            metric(y_batch, y_pred)\n",
    "        print_status_bar(step * batch_size, len(y_train), mean_loss, metrics)\n",
    "    print_status_bar(len(y_train), len(y_train), mean_loss, metrics)\n",
    "    for metric in [mean_loss] + metrics:\n",
    "        metric.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9a587e82fec425197076e93cf608b1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='All epochs', max=5, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e9e39fb31e7403184b45fa2645b2743",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 1/5', max=362, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05d9c331e500444391f22b7ec9b85241",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 2/5', max=362, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "178d9338311c427cb553371bc0e98df7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 3/5', max=362, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b3c03c2904e4e8ab0117595c77773c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 4/5', max=362, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bbee5ec0e904aff8245d58fb174fed8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 5/5', max=362, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from tqdm import tnrange\n",
    "    from collections import OrderedDict\n",
    "    with tnrange(1, n_epochs + 1, desc=\"All epochs\") as epochs:\n",
    "        for epoch in epochs:\n",
    "            with tnrange(1, n_steps + 1, desc=\"Epoch {}/{}\".format(epoch, n_epochs)) as steps:\n",
    "                for step in steps:\n",
    "                    X_batch, y_batch = random_batch(X_train_scaled, y_train)\n",
    "                    with tf.GradientTape() as tape:\n",
    "                        y_pred = model(X_batch)\n",
    "                        main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "                        loss = tf.add_n([main_loss] + model.losses)\n",
    "                    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "                    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "                    for variable in model.variables:\n",
    "                        if variable.constraint is not None:\n",
    "                            variable.assign(variable.constraint(variable))                    \n",
    "                    status = OrderedDict()\n",
    "                    mean_loss(loss)\n",
    "                    status[\"loss\"] = mean_loss.result().numpy()\n",
    "                    for metric in metrics:\n",
    "                        metric(y_batch, y_pred)\n",
    "                        status[metric.name] = metric.result().numpy()\n",
    "                    steps.set_postfix(status)\n",
    "            for metric in [mean_loss] + metrics:\n",
    "                metric.reset_states()\n",
    "except ImportError as ex:\n",
    "    print(\"To run this cell, please install tqdm, ipywidgets and restart Jupyter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cube(x):\n",
    "    return x ** 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1508933, shape=(), dtype=float32, numpy=8.0>"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube(tf.constant(2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.eager.def_function.Function at 0x1421df198>"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube = tf.function(cube)\n",
    "tf_cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1508940, shape=(), dtype=int32, numpy=8>"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1508950, shape=(), dtype=float32, numpy=8.0>"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube(tf.constant(2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF Functions and Concrete Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.framework.func_graph.FuncGraph at 0x14226dba8>"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function = tf_cube.get_concrete_function(tf.constant(2.0))\n",
    "concrete_function.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1508955, shape=(), dtype=float32, numpy=8.0>"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function(tf.constant(2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function is tf_cube.get_concrete_function(tf.constant(2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring Function Definitions and Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.framework.func_graph.FuncGraph at 0x14226dba8>"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'x' type=Placeholder>,\n",
       " <tf.Operation 'pow/y' type=Const>,\n",
       " <tf.Operation 'pow' type=Pow>,\n",
       " <tf.Operation 'Identity' type=Identity>]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ops = concrete_function.graph.get_operations()\n",
    "ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'x:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'pow/y:0' shape=() dtype=float32>]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pow_op = ops[2]\n",
    "list(pow_op.inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'pow:0' shape=() dtype=float32>]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pow_op.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Operation 'x' type=Placeholder>"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function.graph.get_operation_by_name('x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Identity:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function.graph.get_tensor_by_name('Identity:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: \"__inference_cube_1508949\"\n",
       "input_arg {\n",
       "  name: \"x\"\n",
       "  type: DT_FLOAT\n",
       "}\n",
       "output_arg {\n",
       "  name: \"identity\"\n",
       "  type: DT_FLOAT\n",
       "}"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function.function_def.signature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How TF Functions Trace Python Functions to Extract Their Computation Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def tf_cube(x):\n",
    "    print(\"print:\", x)\n",
    "    return x ** 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print: Tensor(\"x:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "result = tf_cube(tf.constant(2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1508968, shape=(), dtype=float32, numpy=8.0>"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print: 2\n",
      "print: 3\n",
      "print: Tensor(\"x:0\", shape=(1, 2), dtype=float32)\n",
      "print: Tensor(\"x:0\", shape=(None, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "result = tf_cube(2)\n",
    "result = tf_cube(3)\n",
    "result = tf_cube(tf.constant([[1., 2.]])) # New shape: trace!\n",
    "result = tf_cube(tf.constant([[3., 4.], [5., 6.]])) # New shape: trace!\n",
    "result = tf_cube(tf.constant([[7., 8.], [9., 10.], [11., 12.]])) # no trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to specify a particular input signature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(input_signature=[tf.TensorSpec([None, 28, 28], tf.float32)])\n",
    "def shrink(images):\n",
    "    print(\"Tracing\", images)\n",
    "    return images[:, ::2, ::2] # drop half the rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing Tensor(\"images:0\", shape=(None, 28, 28), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "img_batch_1 = tf.random.uniform(shape=[100, 28, 28])\n",
    "img_batch_2 = tf.random.uniform(shape=[50, 28, 28])\n",
    "preprocessed_images = shrink(img_batch_1) # Traces the function.\n",
    "preprocessed_images = shrink(img_batch_2) # Reuses the same concrete function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python inputs incompatible with input_signature: inputs ((<tf.Tensor: id=1509032, shape=(2, 2, 2), dtype=float32, numpy=\n",
      "array([[[0.888957  , 0.60685956],\n",
      "        [0.01694834, 0.01444435]],\n",
      "\n",
      "       [[0.7288147 , 0.3239665 ],\n",
      "        [0.45528448, 0.43155968]]], dtype=float32)>,)), input_signature ((TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name=None),))\n"
     ]
    }
   ],
   "source": [
    "img_batch_3 = tf.random.uniform(shape=[2, 2, 2])\n",
    "try:\n",
    "    preprocessed_images = shrink(img_batch_3)  # rejects unexpected types or shapes\n",
    "except ValueError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Autograph To Capture Control Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A \"static\" `for` loop using `range()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def add_10(x):\n",
    "    for i in range(10):\n",
    "        x += 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1509061, shape=(), dtype=int32, numpy=15>"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_10(tf.constant(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'x' type=Placeholder>,\n",
       " <tf.Operation 'add/y' type=Const>,\n",
       " <tf.Operation 'add' type=Add>,\n",
       " <tf.Operation 'add_1/y' type=Const>,\n",
       " <tf.Operation 'add_1' type=Add>,\n",
       " <tf.Operation 'add_2/y' type=Const>,\n",
       " <tf.Operation 'add_2' type=Add>,\n",
       " <tf.Operation 'add_3/y' type=Const>,\n",
       " <tf.Operation 'add_3' type=Add>,\n",
       " <tf.Operation 'add_4/y' type=Const>,\n",
       " <tf.Operation 'add_4' type=Add>,\n",
       " <tf.Operation 'add_5/y' type=Const>,\n",
       " <tf.Operation 'add_5' type=Add>,\n",
       " <tf.Operation 'add_6/y' type=Const>,\n",
       " <tf.Operation 'add_6' type=Add>,\n",
       " <tf.Operation 'add_7/y' type=Const>,\n",
       " <tf.Operation 'add_7' type=Add>,\n",
       " <tf.Operation 'add_8/y' type=Const>,\n",
       " <tf.Operation 'add_8' type=Add>,\n",
       " <tf.Operation 'add_9/y' type=Const>,\n",
       " <tf.Operation 'add_9' type=Add>,\n",
       " <tf.Operation 'Identity' type=Identity>]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_10.get_concrete_function(tf.constant(5)).graph.get_operations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A \"dynamic\" loop using `tf.while_loop()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def add_10(x):\n",
    "    condition = lambda i, x: tf.less(i, 10)\n",
    "    body = lambda i, x: (tf.add(i, 1), tf.add(x, 1))\n",
    "    final_i, final_x = tf.while_loop(condition, body, [tf.constant(0), x])\n",
    "    return final_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1509107, shape=(), dtype=int32, numpy=15>"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_10(tf.constant(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'x' type=Placeholder>,\n",
       " <tf.Operation 'Const' type=Const>,\n",
       " <tf.Operation 'while/maximum_iterations' type=Const>,\n",
       " <tf.Operation 'while/loop_counter' type=Const>,\n",
       " <tf.Operation 'while' type=While>,\n",
       " <tf.Operation 'while/Identity' type=Identity>,\n",
       " <tf.Operation 'while/Identity_1' type=Identity>,\n",
       " <tf.Operation 'while/Identity_2' type=Identity>,\n",
       " <tf.Operation 'while/Identity_3' type=Identity>,\n",
       " <tf.Operation 'Identity' type=Identity>]"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_10.get_concrete_function(tf.constant(5)).graph.get_operations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A \"dynamic\" `for` loop using `tf.range()` (captured by autograph):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def add_10(x):\n",
    "    for i in tf.range(10):\n",
    "        x = x + 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'x' type=Placeholder>,\n",
       " <tf.Operation 'range/start' type=Const>,\n",
       " <tf.Operation 'range/limit' type=Const>,\n",
       " <tf.Operation 'range/delta' type=Const>,\n",
       " <tf.Operation 'range' type=Range>,\n",
       " <tf.Operation 'Const' type=Const>,\n",
       " <tf.Operation 'while/maximum_iterations' type=Const>,\n",
       " <tf.Operation 'while/loop_counter' type=Const>,\n",
       " <tf.Operation 'while' type=While>,\n",
       " <tf.Operation 'while/Identity' type=Identity>,\n",
       " <tf.Operation 'while/Identity_1' type=Identity>,\n",
       " <tf.Operation 'while/Identity_2' type=Identity>,\n",
       " <tf.Operation 'while/Identity_3' type=Identity>,\n",
       " <tf.Operation 'while/Identity_4' type=Identity>,\n",
       " <tf.Operation 'Identity' type=Identity>]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_10.get_concrete_function(tf.constant(0)).graph.get_operations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Variables and Other Resources in TF Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = tf.Variable(0)\n",
    "\n",
    "@tf.function\n",
    "def increment(counter, c=1):\n",
    "    return counter.assign_add(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1509189, shape=(), dtype=int32, numpy=2>"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "increment(counter)\n",
    "increment(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: \"counter\"\n",
       "type: DT_RESOURCE"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_def = increment.get_concrete_function(counter).function_def\n",
    "function_def.signature.input_arg[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = tf.Variable(0)\n",
    "\n",
    "@tf.function\n",
    "def increment(c=1):\n",
    "    return counter.assign_add(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1509207, shape=(), dtype=int32, numpy=2>"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "increment()\n",
    "increment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: \"assignaddvariableop_resource\"\n",
       "type: DT_RESOURCE"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_def = increment.get_concrete_function().function_def\n",
    "function_def.signature.input_arg[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Counter:\n",
    "    def __init__(self):\n",
    "        self.counter = tf.Variable(0)\n",
    "\n",
    "    @tf.function\n",
    "    def increment(self, c=1):\n",
    "        return self.counter.assign_add(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1509225, shape=(), dtype=int32, numpy=2>"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = Counter()\n",
    "c.increment()\n",
    "c.increment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"from __future__ import print_function\\n\\ndef tf__add_10(x):\\n  do_return = False\\n  retval_ = None\\n\\n  def loop_body(loop_vars, x_1):\\n    i = loop_vars\\n    x_1 += 1\\n    return x_1,\\n  x, = ag__.for_stmt(ag__.converted_call('range', tf, ag__.ConversionOptions(recursive=True, verbose=0, strip_decorators=(ag__.convert, ag__.do_not_convert, ag__.converted_call), force_conversion=False, optional_features=(), internal_convert_user_code=True), (10,), {}), None, loop_body, (x,))\\n  do_return = True\\n  retval_ = x\\n  return retval_\\n\\n\\n\\ntf__add_10.autograph_info__ = {}\\n\""
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf.function\n",
    "def add_10(x):\n",
    "    for i in tf.range(10):\n",
    "        x += 1\n",
    "    return x\n",
    "\n",
    "tf.autograph.to_code(add_10.python_function, experimental_optional_features=None)\n",
    "# TODO: experimental_optional_features is needed to have the same behavior as @tf.function,\n",
    "#       check that this is not needed when TF2 is released"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_tf_code(func, experimental_optional_features=None):\n",
    "    from IPython.display import display, Markdown\n",
    "    if hasattr(func, \"python_function\"):\n",
    "        func = func.python_function\n",
    "    code = tf.autograph.to_code(func, experimental_optional_features=experimental_optional_features)\n",
    "    display(Markdown('```python\\n{}\\n```'.format(code)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "from __future__ import print_function\n",
       "\n",
       "def tf__add_10(x):\n",
       "  do_return = False\n",
       "  retval_ = None\n",
       "\n",
       "  def loop_body(loop_vars, x_1):\n",
       "    i = loop_vars\n",
       "    x_1 += 1\n",
       "    return x_1,\n",
       "  x, = ag__.for_stmt(ag__.converted_call('range', tf, ag__.ConversionOptions(recursive=True, verbose=0, strip_decorators=(ag__.convert, ag__.do_not_convert, ag__.converted_call), force_conversion=False, optional_features=(), internal_convert_user_code=True), (10,), {}), None, loop_body, (x,))\n",
       "  do_return = True\n",
       "  retval_ = x\n",
       "  return retval_\n",
       "\n",
       "\n",
       "\n",
       "tf__add_10.autograph_info__ = {}\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_tf_code(add_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using TF Functions with tf.keras (or Not)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, tf.keras will automatically convert your custom code into TF Functions, no need to use\n",
    "`tf.function()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom loss function\n",
    "def my_mse(y_true, y_pred):\n",
    "    print(\"Tracing loss my_mse()\")\n",
    "    return tf.reduce_mean(tf.square(y_pred - y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom metric function\n",
    "def my_mae(y_true, y_pred):\n",
    "    print(\"Tracing metric my_mae()\")\n",
    "    return tf.reduce_mean(tf.abs(y_pred - y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom layer\n",
    "class MyDense(keras.layers.Layer):\n",
    "    def __init__(self, units, activation=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.activation = keras.activations.get(activation)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(name='kernel', \n",
    "                                      shape=(input_shape[1], self.units),\n",
    "                                      initializer='uniform',\n",
    "                                      trainable=True)\n",
    "        self.biases = self.add_weight(name='bias', \n",
    "                                      shape=(self.units,),\n",
    "                                      initializer='zeros',\n",
    "                                      trainable=True)\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, X):\n",
    "        print(\"Tracing MyDense.call()\")\n",
    "        return self.activation(X @ self.kernel + self.biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom model\n",
    "class MyModel(keras.models.Model):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = MyDense(30, activation=\"relu\")\n",
    "        self.hidden2 = MyDense(30, activation=\"relu\")\n",
    "        self.output_ = MyDense(1)\n",
    "\n",
    "    def call(self, input):\n",
    "        print(\"Tracing MyModel.call()\")\n",
    "        hidden1 = self.hidden1(input)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([input, hidden2])\n",
    "        output = self.output_(concat)\n",
    "        return output\n",
    "\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=my_mse, optimizer=\"nadam\", metrics=[my_mae])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing metric my_mae()\n",
      "Tracing metric my_mae()\n",
      "Tracing loss my_mse()\n",
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/2\n",
      "11610/11610 [==============================] - 1s 77us/sample - loss: 1.4017 - my_mae: 0.8108 - val_loss: 0.4857 - val_my_mae: 0.4775\n",
      "Epoch 2/2\n",
      "11610/11610 [==============================] - 1s 50us/sample - loss: 0.4487 - my_mae: 0.4756 - val_loss: 1.0410 - val_my_mae: 0.4636\n",
      "5160/5160 [==============================] - 0s 15us/sample - loss: 0.4326 - my_mae: 0.4597\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.43256516364193703, 0.45965773]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))\n",
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can turn this off by creating the model with `dynamic=True` (or calling `super().__init__(dynamic=True, **kwargs)` in the model's constructor):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(dynamic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=my_mse, optimizer=\"nadam\", metrics=[my_mae])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not the custom code will be called at each iteration. Let's fit, validate and evaluate with tiny datasets to avoid getting too much output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.544255495071411, 2.0656278]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled[:64], y_train[:64], epochs=1,\n",
    "          validation_data=(X_valid_scaled[:64], y_valid[:64]), verbose=0)\n",
    "model.evaluate(X_test_scaled[:64], y_test[:64], verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can compile a model with `run_eagerly=True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=my_mse, optimizer=\"nadam\", metrics=[my_mae], run_eagerly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.633018493652344, 2.0630658]"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled[:64], y_train[:64], epochs=1,\n",
    "          validation_data=(X_valid_scaled[:64], y_valid[:64]), verbose=0)\n",
    "model.evaluate(X_test_scaled[:64], y_test[:64], verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining custom optimizers is not very common, but in case you are one of the happy few who gets to write one, here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMomentumOptimizer(keras.optimizers.Optimizer):\n",
    "    def __init__(self, learning_rate=0.001, momentum=0.9, name=\"MyMomentumOptimizer\", **kwargs):\n",
    "        \"\"\"Call super().__init__() and use _set_hyper() to store hyperparameters\"\"\"\n",
    "        super().__init__(name, **kwargs)\n",
    "        self._set_hyper(\"learning_rate\", kwargs.get(\"lr\", learning_rate)) # handle lr=learning_rate\n",
    "        self._set_hyper(\"decay\", self._initial_decay) # \n",
    "        self._set_hyper(\"momentum\", momentum)\n",
    "    \n",
    "    def _create_slots(self, var_list):\n",
    "        \"\"\"For each model variable, create the optimizer variable associated with it.\n",
    "        TensorFlow calls these optimizer variables \"slots\".\n",
    "        For momentum optimization, we need one momentum slot per model variable.\n",
    "        \"\"\"\n",
    "        for var in var_list:\n",
    "            self.add_slot(var, \"momentum\")\n",
    "\n",
    "    @tf.function\n",
    "    def _resource_apply_dense(self, grad, var):\n",
    "        \"\"\"Update the slots and perform one optimization step for one model variable\n",
    "        \"\"\"\n",
    "        var_dtype = var.dtype.base_dtype\n",
    "        lr_t = self._decayed_lr(var_dtype) # handle learning rate decay\n",
    "        momentum_var = self.get_slot(var, \"momentum\")\n",
    "        momentum_hyper = self._get_hyper(\"momentum\", var_dtype)\n",
    "        momentum_var.assign(momentum_var * momentum_hyper - (1. - momentum_hyper)* grad)\n",
    "        var.assign_add(momentum_var * lr_t)\n",
    "\n",
    "    def _resource_apply_sparse(self, grad, var):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {\n",
    "            **base_config,\n",
    "            \"learning_rate\": self._serialize_hyperparameter(\"learning_rate\"),\n",
    "            \"decay\": self._serialize_hyperparameter(\"decay\"),\n",
    "            \"momentum\": self._serialize_hyperparameter(\"momentum\"),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "11610/11610 [==============================] - 0s 33us/sample - loss: 4.6747\n",
      "Epoch 2/5\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 1.4888\n",
      "Epoch 3/5\n",
      "11610/11610 [==============================] - 0s 25us/sample - loss: 0.8565\n",
      "Epoch 4/5\n",
      "11610/11610 [==============================] - 0s 25us/sample - loss: 0.7086\n",
      "Epoch 5/5\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.6652\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x145154e48>"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([keras.layers.Dense(1, input_shape=[8])])\n",
    "model.compile(loss=\"mse\", optimizer=MyMomentumOptimizer())\n",
    "model.fit(X_train_scaled, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "- Chapter 12 – Custom Models and Training with TensorFlow of <Hands-on Machine Learning with Scikit-learn and Tensorflow>, ed2. (primary source)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
