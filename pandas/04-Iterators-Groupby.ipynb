{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topics\n",
    "\n",
    "- Stream larger-than-memory data through a pipeline\n",
    "- Composable thanks to the iterator protocol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My favorite \"feature\" of pandas is that it's written in Python.\n",
    "Python has great language-level features for handling streams of data\n",
    "that may not fit in memory.\n",
    "This can be a useful pre-processing step to reading the data into a DataFrame or\n",
    "NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "from pathlib import Path\n",
    "from itertools import islice, takewhile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import dask.dataframe as dd\n",
    "from toolz import partition_all, partitionby\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 10\n",
    "sns.set(context='talk')\n",
    "plt.style.use(\"default\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beer Reviews Dataset\n",
    "\n",
    "- A review is a list of lines\n",
    "- Each review line is formated like `meta/field: value`\n",
    "- Reviews are separated by blank lines (i.e. the line is just `'\\n'`)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stanford has a [dataset on beer reviews](https://snap.stanford.edu/data/web-BeerAdvocate.html). The raw file is too large for me to include, but I split off a couple subsets for us to work with.\n",
    "\n",
    "Pandas can't read this file natively, but we have Python!\n",
    "We'll use Python to parse the raw file and tranform it into a tabular format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with gzip.open(\"data/beer-raw-small.txt.gz\", \"r\") as f:\n",
    "    print(f.read(1500).decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full compressed raw dataset is about 500MB, so reading it all into memory might not be pleasent (we're working with a small subset that would fit in memory, but pretend it didn't).\n",
    "Fortunately, Python's iterator protocol and generators make dealing with large streams of data pleasent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Developing a solution\n",
    "\n",
    "Let's build a solution together. I'll provide some guidance as we go along."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a handle to the data\n",
    "f = gzip.open(\"data/beer-raw-small.txt.gz\", \"rt\")\n",
    "f.readline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing Tasks\n",
    "\n",
    "1. split the raw text stream into individual reviews\n",
    "2. transform each individual review into a data container\n",
    "3. combine a chunk of transformed individual reviews into a collection\n",
    "4. store the chunk to disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1**: Split the text stream\n",
    "\n",
    "We'll use `toolz.partitionby`. It takes an iterator like `f`, and splits it according to `func`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.seek(0)  # Make the cell idempotent\n",
    "split = partitionby(lambda x: x == '\\n', f)\n",
    "a, b = next(split), next(split)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we've gone from\n",
    "\n",
    "```python\n",
    "[\n",
    "    \"beer/name: Susa Weizen\\n\",\n",
    "    ...\n",
    "    \"review/text: ...\\n\",\n",
    "    \"\\n\",\n",
    "    \"beer/name: Beer 2\\n\",\n",
    "    \"...\",\n",
    "    \"review/text: ...\\n\",\n",
    "    \"\\n\",\n",
    "]\n",
    "```\n",
    "\n",
    "To\n",
    "\n",
    "```python\n",
    "[\n",
    "    (\n",
    "        \"beer/name Susa Weizen\\n\",\n",
    "        ...\n",
    "        \"review/text: ...\\n\"\n",
    "    ),\n",
    "    (\"\\n\",),\n",
    "    (\n",
    "        \"beer/name: Beer 2\\n\",\n",
    "        ...\n",
    "        \"review/text: ...\\n\"\n",
    "    ),\n",
    "    (\"\\n\",),\n",
    "    ...\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can clean up those newlines with a generator expression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.seek(0)\n",
    "reviews = (x for x in partitionby(lambda x: x == \"\\n\", f)\n",
    "           if x != (\"\\n\",))\n",
    "reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2**: Parse each review\n",
    "\n",
    "Let's grab out the first review, and turn it into something a bit nicer than a tuple of strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.seek(0);  # make the cell idempotent\n",
    "review = next(partitionby(lambda x: x == '\\n', f))\n",
    "review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" data-title=\"Format Review\">\n",
    "  <h1><i class=\"fa fa-tasks\" aria-hidden=\"true\"></i> Exercise: Format Review</h1>\n",
    "</div>\n",
    "<p>Write a function `format_review` that converts an item like `review` into a dict</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will have one entry per line, where the are the stuff to the left of the colon and the values are the stuff to the right.\n",
    "For example, the first line would be\n",
    "\n",
    "`'beer/name: Sausa Weizen\\n',` => `'beer/name': 'Sausa Weizen'`\n",
    "\n",
    "Make sure to clean up the line endings too.\n",
    "\n",
    "- Hint: Check out the [python string methods](https://docs.python.org/3/library/stdtypes.html#string-methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check your function against `expected` by evaluating the next cell.\n",
    "If you get a failure, adjust your `format_review` until it passes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "from typing import List, Dict\n",
    "\n",
    "f.seek(0);  # make the cell idempotent\n",
    "review = next(partitionby(lambda x: x == '\\n', f))\n",
    "\n",
    "\n",
    "def format_review(review):\n",
    "    \"\"\"Your code goes below\"\"\"\n",
    "    formatted = dict([line.strip('\\n').split(\": \", 1) for line in review])\n",
    "    return formatted\n",
    "    \n",
    "\n",
    "class TestFormat(unittest.TestCase):\n",
    "    maxDiff = None\n",
    "\n",
    "    def test_format_review(self):\n",
    "        result = format_review(review)\n",
    "        expected = {\n",
    "            'beer/ABV': '5.00',\n",
    "            'beer/beerId': '47986',\n",
    "            'beer/brewerId': '10325',\n",
    "            'beer/name': 'Sausa Weizen',\n",
    "            'beer/style': 'Hefeweizen',\n",
    "            'review/appearance': '2.5',\n",
    "            'review/aroma': '2',\n",
    "            'review/overall': '1.5',\n",
    "            'review/palate': '1.5',\n",
    "            'review/profileName': 'stcules',\n",
    "            'review/taste': '1.5',\n",
    "            'review/text': 'A lot of foam. But a lot.\\tIn the smell some banana, and then lactic and tart. Not a good start.\\tQuite dark orange in color, with a lively carbonation (now visible, under the foam).\\tAgain tending to lactic sourness.\\tSame for the taste. With some yeast and banana.\\t\\t',\n",
    "            'review/time': '1234817823'\n",
    "        }\n",
    "        self.assertEqual(result, expected)\n",
    "\n",
    "suite = unittest.TestLoader().loadTestsFromModule(TestFormat())\n",
    "unittest.TextTestRunner().run(suite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that optional argument to split, which controls the number of splits made; If a review text had contained a literal `': '`, we'd be in trouble since it'd get split again.\n",
    "\n",
    "Make sure you executed the above solution cell twice (first to load, second to execute) as we'll be using that `format_review` function down below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To a DataFrame\n",
    "\n",
    "Assuming we've processed many reviews into a list, we'll then build up a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = [format_review(review)]  # imagine a list of many reviews\n",
    "\n",
    "col_names = {\n",
    "    'beer/ABV': 'abv',\n",
    "    'beer/beerId': 'beer_id',\n",
    "    'beer/brewerId': 'brewer_id',\n",
    "    'beer/name': 'beer_name',\n",
    "    'beer/style': 'beer_style',\n",
    "    'review/appearance': 'review_appearance',\n",
    "    'review/aroma': 'review_aroma',\n",
    "    'review/overall': 'review_overall',\n",
    "    'review/palate': 'review_palate',\n",
    "    'review/profileName': 'profile_name',\n",
    "    'review/taste': 'review_taste',\n",
    "    'review/text': 'text',\n",
    "    'review/time': 'time'\n",
    "}\n",
    "df = pd.DataFrame(r)\n",
    "numeric = ['abv', 'review_appearance', 'review_aroma',\n",
    "           'review_overall', 'review_palate', 'review_taste']\n",
    "df = (df.rename(columns=col_names)\n",
    "        .replace('', np.nan))\n",
    "df[numeric] = df[numeric].astype(float)\n",
    "df['time'] = pd.to_datetime(df.time.astype(int), unit='s')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, writing that as a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def as_dataframe(reviews):\n",
    "    df = pd.DataFrame(list(reviews))\n",
    "\n",
    "    col_names = {\n",
    "        'beer/ABV': 'abv',\n",
    "        'beer/beerId': 'beer_id',\n",
    "        'beer/brewerId': 'brewer_id',\n",
    "        'beer/name': 'beer_name',\n",
    "        'beer/style': 'beer_style',\n",
    "        'review/appearance': 'review_appearance',\n",
    "        'review/aroma': 'review_aroma',\n",
    "        'review/overall': 'review_overall',\n",
    "        'review/palate': 'review_palate',\n",
    "        'review/profileName': 'profile_name',\n",
    "        'review/taste': 'review_taste',\n",
    "        'review/text': 'text',\n",
    "        'review/time': 'time'\n",
    "    }\n",
    "    order = ['brewer_id', 'beer_id', 'beer_name',\n",
    "             'beer_style', 'abv',\n",
    "             'profile_name', 'time',\n",
    "             'review_appearance', 'review_aroma',\n",
    "             'review_palate', 'review_taste',\n",
    "             'review_overall',\n",
    "             'text']\n",
    "    df = df.rename(columns=col_names)[order]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full pipeline\n",
    "\n",
    "1. `file -> review_lines : List[str]`\n",
    "2. `review_lines -> reviews : Dict[str, str]`\n",
    "3. `reviews -> DataFrames`\n",
    "4. `DataFrames -> CSV`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full pipeline would look something like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100  # Number of reviews to process per chunk\n",
    "                  # Intentionally small for demonstration    \n",
    "p = Path(\"data/beer-raw-small.txt.gz\")\n",
    "\n",
    "with gzip.open(p, \"rt\") as f:\n",
    "    \n",
    "    review_lines_and_newlines = partitionby(lambda x: x == '\\n', f)\n",
    "    # so filter out the newlines\n",
    "    review_lines = (x for x in review_lines_and_newlines if x != (\"\\n\",))\n",
    "    \n",
    "    # generator expression to go from List[str] -> Dict[str, str]\n",
    "    reviews = (format_review(x) for x in review_lines)\n",
    "    \n",
    "    # `reviews` yields one dict per review.\n",
    "    # Won't fit in memory, so do `BATCH_SIZE` per chunk\n",
    "    chunks = partition_all(BATCH_SIZE, reviews)\n",
    "    dfs = (as_dataframe(chunk) for chunk in chunks)\n",
    "\n",
    "    p.parent.joinpath(\"beer\").mkdir(exist_ok=True)\n",
    "\n",
    "    # the first time we read from disk\n",
    "    for i, df in enumerate(dfs):\n",
    "        df.to_csv(\"data/beer/chunk_%s.csv.gz\" % i, index=False,\n",
    "                  compression=\"gzip\")\n",
    "        print(i, end='\\r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This runs comfortably in memory. At any given time, we only have `BATCH_SIZE` reviews in memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brief Aside on [Dask](http://dask.pydata.org/en/latest/)\n",
    "\n",
    "> Dask is a flexible parallel computing library for analytic computing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(Postpone and read Dask in some details in future!)**\n",
    "\n",
    "The original dataset is in random order, but I wanted to select an interesting subset for us to work on: all the reviews by the top 100 reviewers.\n",
    "\n",
    "You might know enough pandas now to figure out the top-100 reviewers by count.\n",
    "Do a `value_counts` , select the top 100, then select the index.\n",
    "\n",
    "```python\n",
    "top_reviewers = df.profile_name.value_counts().nlargest(100).index\n",
    "```\n",
    "\n",
    "\n",
    "Recall that `value_counts` will be a `Series` where the index is each unique `profile_name` and the values is the count of reviews for that profile.\n",
    "We use `nlargets(100)` to get the 100 largest values, and `.index` to get the actual profile names. \n",
    "\n",
    "With that we could do an `isin` like\n",
    "\n",
    "```python\n",
    "subset = df[df.profile_name.isin(top_reviewers)\n",
    "```\n",
    "\n",
    "To get the subset of reviews that came from the 100 most active reviewers.\n",
    "\n",
    "But that assumes we have a `df` containing the full dataset in memory.\n",
    "My laptop can't load the entire dataset though (recall that we're working with a subset today).\n",
    "\n",
    "It wouldn't be *that* hard to write a custom solution in python or pandas using chunking like we did up above.\n",
    "We'd split our task into parts\n",
    "\n",
    "- read a chunk\n",
    "- compute `chunk.profile_name.value_counts()`\n",
    "- store that intermediate `value_counts` in a global container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figures/map-reduce-count.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we've processed each chunk, our final steps are to\n",
    "\n",
    "- merge each `value_counts` chunk by summing\n",
    "- filter to the top 100\n",
    "\n",
    "This pattern of processing chunks independently (map) and combining the results into a smaller output (reduce) is common, and doing it manually gets old.\n",
    "Dask can help out here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collections, Tasks, Schedulers\n",
    "\n",
    "![](http://dask.pydata.org/en/latest/_images/collections-schedulers.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dask has several components, so it can be hard to succinctly describe the library.\n",
    "Right now, we'll view it as providing \"big dataframes\" (one of its \"collections\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dd.read_csv(\"data/beer/chunk*.csv.gz\", compression=\"gzip\", blocksize=None,\n",
    "                 parse_dates=['time'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That API should look familiar to you, now that you're experienced pandas users.\n",
    "We swap out `pd` for `dd`, and stuff mostly just works.\n",
    "Occasionally, you'll have a `dask`-specific thing like `blocksize` (number of bytes per smaller dataframe) that don't apply to pandas, which assumes things fit in memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our \"big dataframe\", we can do normal pandas operations like `.value_counts`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_per_person = df.profile_name.value_counts()\n",
    "reviews_per_person"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a `dask.Series`, the dask analog to a `dask.dataframe`.\n",
    "One important point: we haven't actually done any real work yet.\n",
    "The operations on a `dask.dataframe` is really just a pandas-like API for\n",
    "manipulating the directed acylic graph (DAG) of operations, and a bit of metadata about those operations.\n",
    "We can visualize that DAG with the `.visualize` method. I've done it ahead of\n",
    "time since it uses `graphviz`, which can be a pain to install on every system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "reviews_per_person.visualize(rankdir=\"LR\")\n",
    "```\n",
    "\n",
    "![](figures/reviews_per_person.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the 100 most active reviewers. There's a couple ways to do this.\n",
    "\n",
    "1. Sort `reviews_per_person`, then take the the last 100\n",
    "2. Scan `reviews_per_person`, keeps the 100 largest you've seen\n",
    "\n",
    "For large datasets, 2 is *much* easier / faster. It's implemented as `.nlargest` on pandas and dask Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_reviewers = reviews_per_person.nlargest(100).index\n",
    "top_reviewers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we still just have a dask object (a DAG of operations, to be computed later). To actually get a concrete value, you hand the DAG off to a *scheduler*, using `compute`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_reviewers.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`dask.dataframe` uses the threaded scheduler, so the actual computation is done in parallel. You could also use the `multiprocessing` scheduler (if you have operations that hold the GIL), or the `distributed` scheduler if you have a cluster handy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `top_reviewers` as a boolean mask, just like in regular pandas.\n",
    "\n",
    "```python\n",
    ">>> df[df.profile_name.isin(top_reviewers.compute())].to_parquet(\n",
    "    \"data/subset.parq\", compression='gzip'\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back to pandas\n",
    "\n",
    "I've provided the reviews by the top 100 reviewers.\n",
    "We'll use it for talking about groupby."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"data/subset.parq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" data-title=\"Reviews by Hour\">\n",
    "  <h1><i class=\"fa fa-tasks\" aria-hidden=\"true\"></i> Exercise: Reviews by Hour</h1>\n",
    "</div>\n",
    "\n",
    "<p>Make a barplot of the count of reviews by hour of the day.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Hint: Use the `.dt` namespace to get the `hour` component of a `datetime`\n",
    "- Hint: We've seen `Series.value_counts` for getting the count of each value\n",
    "- Hint: Use `.sort_index` to make sure the data is ordered by hour, not count\n",
    "- Hint: Use the [`.plot`](http://pandas.pydata.org/pandas-docs/stable/api.html#plotting) namespace to get a `bar` chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.time.dt.hour\n",
    "   .value_counts()\n",
    "   .sort_index()\n",
    "   .plot.bar(rot=0, color='k', width=.8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" data-title=\"Pale Ales\">\n",
    "  <h1><i class=\"fa fa-tasks\" aria-hidden=\"true\"></i> Exercise: Pale Ales</h1>\n",
    "</div>\n",
    "<p>\n",
    "Make a variable `pale_ales` that filters `df` to just rows where `beer_style` contains the string `'pale ale'` (ignoring case)\n",
    "</p>\n",
    "- Hint: Use the `df.beer_style.str` namespace and find a method for checking whether a string contains another string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pas = df[df.beer_style.str.contains('pale ale', case=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Groupby"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Groupby operations come up in a lot of contexts.\n",
    "At its root, groupby about doing an operation on many subsets of the data, each of which shares something in common.\n",
    "The components of a groupby operation are:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Components of a groupby\n",
    "\n",
    "1. **split** a table into groups\n",
    "2. **apply** a function to each group\n",
    "3. **combine** the results into a single DataFrame or Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In pandas the `split` step looks like\n",
    "\n",
    "```python\n",
    "df.groupby( grouper )\n",
    "```\n",
    "\n",
    "`grouper` can be many things\n",
    "\n",
    "- Series (or string indicating a column in `df`); the Series must be of same length to the rows of the DataFrame.\n",
    "- function (to be applied on the index)\n",
    "- dict : groups by *values*\n",
    "- `levels=[ names of levels in a MultiIndex ]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split\n",
    "\n",
    "Break a table into smaller logical tables according to some rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr = df.groupby(\"beer_name\")\n",
    "gr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We haven't really done any actual work yet, but pandas knows what it needs to know to break the larger `df` into many smaller pieces, one for each distinct `beer_name`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply & Combine\n",
    "\n",
    "To finish the groupby, we apply a method to the groupby object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_cols = ['review_appearance', 'review_aroma', 'review_overall',\n",
    "               'review_palate', 'review_taste']\n",
    "\n",
    "df.groupby('beer_name')[review_cols].agg('mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the function we applied was `'mean'`.\n",
    "Pandas has implemented cythonized versions of certain common methods like mean, sum, etc.\n",
    "You can also pass in regular functions like `np.mean`.\n",
    "\n",
    "In terms of split, apply, combine, split was `df.groupby('beer_name')`. \n",
    "We apply the `mean` function by passing in `'mean'`.\n",
    "Finally, by using the `.agg` method (for aggregate) we tell pandas to combine the results with one output row per group.\n",
    "\n",
    "You can also pass in regular functions like `np.mean`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('beer_name')[review_cols].agg(np.mean).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, [certain methods](http://pandas.pydata.org/pandas-docs/stable/api.html#id35) have been attached to `Groupby` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('beer_name')[review_cols].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" data-title=\"Highest Variance\">\n",
    "  <h1><i class=\"fa fa-tasks\" aria-hidden=\"true\"></i> Exercise: Highest Variance</h1>\n",
    "</div>\n",
    "\n",
    "<p>Find the `beer_style`s with the greatest variance in `abv`.</p>\n",
    "\n",
    "- hint: `.var` calculates the varaince and is available on `GroupBy` objects like `gr.abv`.\n",
    "- hint: use `.sort_values` to sort a Series by the values (it took us a while to come up with that name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('beer_style').abv.var().sort_values(ascending=False).index[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `.agg` output shape\n",
    "\n",
    "The output shape is determined by the grouper, data, and aggregation\n",
    "\n",
    "- Grouper: Controls the output index\n",
    "    * single grouper -> Index\n",
    "    * array-like grouper -> MultiIndex\n",
    "- Subject (Groupee): Controls the output data values\n",
    "    * single column -> Series (or DataFrame if multiple aggregations)\n",
    "    * multiple columns -> DataFrame\n",
    "- Aggregation: Controls the output columns\n",
    "    * single aggfunc -> Index in the colums\n",
    "    * multiple aggfuncs -> MultiIndex in the columns (Or 1-D Index if groupee is 1-D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We'll go into MultiIndexes in a bit, but for know, think of them as regular Indexes with multiple levels (columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single grouper, single groupee, single aggregation\n",
    "df.groupby('beer_style').review_overall.agg('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiple groupers, multiple groupee, single aggregation\n",
    "df.groupby(['brewer_id', 'beer_name'])[review_cols].agg(['mean', 'min', 'max', 'std', 'count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" data-title=\"Rating by length\">\n",
    "  <h1><i class=\"fa fa-tasks\" aria-hidden=\"true\"></i> Exercise: Rating by length</h1>\n",
    "</div>\n",
    "\n",
    "<p>Plot the relationship between review length (number of characters) and average `reveiw_overall`.</p>\n",
    "\n",
    "- Hint: use `.plot(style='k.')`\n",
    "- We've grouped by columns so far, you can also group by any series with the same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is groupby Series.\n",
    "review_length = df.text.str.len()\n",
    "gr = df.groupby(review_length).review_overall\n",
    "gr.mean().plot(style='k.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" data-title=\"Reviews by Length\">\n",
    "  <h1><i class=\"fa fa-tasks\" aria-hidden=\"true\"></i> Exercise: Reviews by Length</h1>\n",
    "</div>\n",
    "\n",
    "<p>Find the relationship between review length (number of **words** and average `reveiw_overall`.)</p>\n",
    "\n",
    "- Hint: You can pass a [regular expression](https://docs.python.org/3/howto/regex.html#matching-characters) to any of the `.str` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.groupby(df.text.str.count('\\w'))\n",
    "   .review_overall\n",
    "   .mean().plot(style='k.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" data-title=\"Rating by number of Reviews\">\n",
    "  <h1><i class=\"fa fa-tasks\" aria-hidden=\"true\"></i> Exercise: Rating by number of Reviews</h1>\n",
    "</div>\n",
    "\n",
    "<p>Find the relationship between the number of reviews for a beer and the average `review_overall`.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.groupby('beer_id')\n",
    "   .review_overall\n",
    "   .agg(['mean', 'count'])\n",
    "   .plot.scatter(x='count', y='mean', color='k',\n",
    "                 marker='.', alpha=.25));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform\n",
    "\n",
    "A *transform* is a function whose output is the same shape as the input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that a groupby has three steps: split, apply, combine.\n",
    "So far, all of the functions we've applied have been *aggregations*: the rule for \"combine\" is one row per group.\n",
    "\n",
    "You can use `Groupby.transform` when you have an operation that should be done *groupwise*, but the result should be the same shape.\n",
    "For example, suppose we wanted to de-mean each reviewer's scores by their average score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define demean(v: array) -> array\n",
    "def demean(v):\n",
    "    return v - v.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just calling `demean` on the entire Series will noramilze by the *global* average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demean(df.review_overall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's de-mean each individual's reviews by their own average.\n",
    "This could be useful if, for example, you were building a recommendation system.\n",
    "A rating of 4 from someone's whose average is 2 is in some sense more meaningful that a 4 from someone who always gives 4s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized = df.groupby(\"profile_name\")[review_cols].transform(demean)\n",
    "normalized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used `.transform` because the desired output was the same shape as the input.\n",
    "Just like `.agg` informs pandas that you want `1 input group → 1 output row`, the `.transform` method informs pandas that you want `1 input row → 1 output row`.\n",
    "\n",
    "`.transform` operates on each column independently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" data-title=\"Personal Trend?\">\n",
    "  <h1><i class=\"fa fa-tasks\" aria-hidden=\"true\"></i> Exercise: Personal Trend?</h1>\n",
    "</div>\n",
    "\n",
    "<p>Do reviewer's `review_overall` trend over a person's time reviewing?</p>\n",
    "\n",
    "Hint: Need an indictor that tracks which review this is for that person. That is, we need a cumulative count of reviews per person. - **(don't quite understand what this means.)**\n",
    "\n",
    "Implement `cumcount` to match the example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cumcount(s):\n",
    "    \"\"\"Returns an array with counting up to the length of 's'\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> cumcount([1, 2, 2, 1, 2])\n",
    "    array([0, 1, 2, 4])\n",
    "    \"\"\"\n",
    "    return ...\n",
    "\n",
    "cumcount([1, 2, 2, 1, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now make a variable `order` that has which review it was for that person.\n",
    "For example, if the raw reviews were like\n",
    "\n",
    "<table>\n",
    "  <thead>\n",
    "      <th>Reviewer</th>\n",
    "      <th>Review Overall</th>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "      <tr>\n",
    "          <td>Alice</td>\n",
    "          <td>3</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "          <td>Alice</td>\n",
    "          <td>3</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "          <td>Bob</td>\n",
    "          <td>2</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "          <td>Alice</td>\n",
    "          <td>4</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "          <td>Bob</td>\n",
    "          <td>5</td>\n",
    "      </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "The `order` table would be\n",
    "\n",
    "\n",
    "<table>\n",
    "  <thead>\n",
    "      <th>Reviewer</th>\n",
    "      <th>Order</th>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "      <tr>\n",
    "          <td>Alice</td>\n",
    "          <td>0</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "          <td>Alice</td>\n",
    "          <td>1</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "          <td>Bob</td>\n",
    "          <td>0</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "          <td>Alice</td>\n",
    "          <td>2</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "          <td>Bob</td>\n",
    "          <td>2</td>\n",
    "      </tr>\n",
    "  </tbody>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = df.groupby(\"profile_name\").review_overall.transform(...)\n",
    "order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, what do we do with `order`? Hint: It's the same shape as `df` and we\n",
    "want to compute the average `review_overall` for all people with `order=0`,\n",
    "and all people with `order=1`, and `order=2`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/groupby_02.py\n",
    "order = df.groupby(\"profile_name\").review_overall.cumcount()\n",
    "df.groupby(order).review_overall.mean().plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General `.apply`\n",
    "\n",
    "We've seen `.agg` for outputting 1 row per group, and `.transform` for outputting 1 row per input row.\n",
    "\n",
    "The final kind of function application is `.apply`.\n",
    "This can do pretty much whatever you want. To be more precise, the groupby **`apply`** method can return a single value, a Series or a DataFrame. You must supply a custom function to **`apply`**. This custom function accepts the entire group as a **`DataFrame`**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INSTNM</th>\n",
       "      <th>CITY</th>\n",
       "      <th>STABBR</th>\n",
       "      <th>HBCU</th>\n",
       "      <th>MENONLY</th>\n",
       "      <th>WOMENONLY</th>\n",
       "      <th>RELAFFIL</th>\n",
       "      <th>SATVRMID</th>\n",
       "      <th>SATMTMID</th>\n",
       "      <th>DISTANCEONLY</th>\n",
       "      <th>...</th>\n",
       "      <th>UGDS_2MOR</th>\n",
       "      <th>UGDS_NRA</th>\n",
       "      <th>UGDS_UNKN</th>\n",
       "      <th>PPTUG_EF</th>\n",
       "      <th>CURROPER</th>\n",
       "      <th>PCTPELL</th>\n",
       "      <th>PCTFLOAN</th>\n",
       "      <th>UG25ABV</th>\n",
       "      <th>MD_EARN_WNE_P10</th>\n",
       "      <th>GRAD_DEBT_MDN_SUPP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama A &amp; M University</td>\n",
       "      <td>Normal</td>\n",
       "      <td>AL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>424.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0656</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7356</td>\n",
       "      <td>0.8284</td>\n",
       "      <td>0.1049</td>\n",
       "      <td>30300</td>\n",
       "      <td>33888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>University of Alabama at Birmingham</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>AL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>570.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.0179</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.2607</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3460</td>\n",
       "      <td>0.5214</td>\n",
       "      <td>0.2422</td>\n",
       "      <td>39700</td>\n",
       "      <td>21941.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amridge University</td>\n",
       "      <td>Montgomery</td>\n",
       "      <td>AL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2715</td>\n",
       "      <td>0.4536</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6801</td>\n",
       "      <td>0.7795</td>\n",
       "      <td>0.8540</td>\n",
       "      <td>40100</td>\n",
       "      <td>23370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>University of Alabama in Huntsville</td>\n",
       "      <td>Huntsville</td>\n",
       "      <td>AL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>595.0</td>\n",
       "      <td>590.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0172</td>\n",
       "      <td>0.0332</td>\n",
       "      <td>0.0350</td>\n",
       "      <td>0.2146</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3072</td>\n",
       "      <td>0.4596</td>\n",
       "      <td>0.2640</td>\n",
       "      <td>45500</td>\n",
       "      <td>24097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alabama State University</td>\n",
       "      <td>Montgomery</td>\n",
       "      <td>AL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>425.0</td>\n",
       "      <td>430.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0243</td>\n",
       "      <td>0.0137</td>\n",
       "      <td>0.0892</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7347</td>\n",
       "      <td>0.7554</td>\n",
       "      <td>0.1270</td>\n",
       "      <td>26600</td>\n",
       "      <td>33118.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                INSTNM        CITY STABBR  HBCU  MENONLY  \\\n",
       "0             Alabama A & M University      Normal     AL   1.0      0.0   \n",
       "1  University of Alabama at Birmingham  Birmingham     AL   0.0      0.0   \n",
       "2                   Amridge University  Montgomery     AL   0.0      0.0   \n",
       "3  University of Alabama in Huntsville  Huntsville     AL   0.0      0.0   \n",
       "4             Alabama State University  Montgomery     AL   1.0      0.0   \n",
       "\n",
       "   WOMENONLY  RELAFFIL  SATVRMID  SATMTMID  DISTANCEONLY         ...          \\\n",
       "0        0.0         0     424.0     420.0           0.0         ...           \n",
       "1        0.0         0     570.0     565.0           0.0         ...           \n",
       "2        0.0         1       NaN       NaN           1.0         ...           \n",
       "3        0.0         0     595.0     590.0           0.0         ...           \n",
       "4        0.0         0     425.0     430.0           0.0         ...           \n",
       "\n",
       "   UGDS_2MOR  UGDS_NRA  UGDS_UNKN  PPTUG_EF  CURROPER  PCTPELL  PCTFLOAN  \\\n",
       "0     0.0000    0.0059     0.0138    0.0656         1   0.7356    0.8284   \n",
       "1     0.0368    0.0179     0.0100    0.2607         1   0.3460    0.5214   \n",
       "2     0.0000    0.0000     0.2715    0.4536         1   0.6801    0.7795   \n",
       "3     0.0172    0.0332     0.0350    0.2146         1   0.3072    0.4596   \n",
       "4     0.0098    0.0243     0.0137    0.0892         1   0.7347    0.7554   \n",
       "\n",
       "   UG25ABV  MD_EARN_WNE_P10  GRAD_DEBT_MDN_SUPP  \n",
       "0   0.1049            30300               33888  \n",
       "1   0.2422            39700             21941.5  \n",
       "2   0.8540            40100               23370  \n",
       "3   0.2640            45500               24097  \n",
       "4   0.1270            26600             33118.5  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Introducing a new dataset college\n",
    "college = pd.read_csv('data/college.csv')\n",
    "college.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple examples to see how the groupby `apply` works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_single(x):\n",
    "    return 'a single value'\n",
    "\n",
    "def return_series(x):\n",
    "    return pd.Series(data=['value 1', 'value 2'], index=['col A', 'col B'])\n",
    "\n",
    "def return_df(x):\n",
    "    return pd.DataFrame(np.random.rand(3,2), \n",
    "                        index=['row one', 'row two', 'row three'], \n",
    "                        columns=['col A', 'col B'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STABBR  RELAFFIL\n",
       "AK      0           a single value\n",
       "        1           a single value\n",
       "AL      0           a single value\n",
       "        1           a single value\n",
       "AR      0           a single value\n",
       "        1           a single value\n",
       "AS      0           a single value\n",
       "AZ      0           a single value\n",
       "        1           a single value\n",
       "CA      0           a single value\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college.groupby(['STABBR', 'RELAFFIL']).apply(return_single).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>col A</th>\n",
       "      <th>col B</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STABBR</th>\n",
       "      <th>RELAFFIL</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">AK</th>\n",
       "      <th>0</th>\n",
       "      <td>value 1</td>\n",
       "      <td>value 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>value 1</td>\n",
       "      <td>value 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">AL</th>\n",
       "      <th>0</th>\n",
       "      <td>value 1</td>\n",
       "      <td>value 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>value 1</td>\n",
       "      <td>value 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">AR</th>\n",
       "      <th>0</th>\n",
       "      <td>value 1</td>\n",
       "      <td>value 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>value 1</td>\n",
       "      <td>value 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AS</th>\n",
       "      <th>0</th>\n",
       "      <td>value 1</td>\n",
       "      <td>value 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">AZ</th>\n",
       "      <th>0</th>\n",
       "      <td>value 1</td>\n",
       "      <td>value 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>value 1</td>\n",
       "      <td>value 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <th>0</th>\n",
       "      <td>value 1</td>\n",
       "      <td>value 2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   col A    col B\n",
       "STABBR RELAFFIL                  \n",
       "AK     0         value 1  value 2\n",
       "       1         value 1  value 2\n",
       "AL     0         value 1  value 2\n",
       "       1         value 1  value 2\n",
       "AR     0         value 1  value 2\n",
       "       1         value 1  value 2\n",
       "AS     0         value 1  value 2\n",
       "AZ     0         value 1  value 2\n",
       "       1         value 1  value 2\n",
       "CA     0         value 1  value 2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college.groupby(['STABBR', 'RELAFFIL']).apply(return_series).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>col A</th>\n",
       "      <th>col B</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STABBR</th>\n",
       "      <th>RELAFFIL</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">AK</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0</th>\n",
       "      <th>row one</th>\n",
       "      <td>0.864879</td>\n",
       "      <td>0.085312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row two</th>\n",
       "      <td>0.539662</td>\n",
       "      <td>0.762609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row three</th>\n",
       "      <td>0.149195</td>\n",
       "      <td>0.214124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1</th>\n",
       "      <th>row one</th>\n",
       "      <td>0.838426</td>\n",
       "      <td>0.444579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row two</th>\n",
       "      <td>0.895184</td>\n",
       "      <td>0.217259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row three</th>\n",
       "      <td>0.323294</td>\n",
       "      <td>0.174294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">AL</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0</th>\n",
       "      <th>row one</th>\n",
       "      <td>0.301533</td>\n",
       "      <td>0.710610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row two</th>\n",
       "      <td>0.980481</td>\n",
       "      <td>0.653199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row three</th>\n",
       "      <td>0.199440</td>\n",
       "      <td>0.465990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1</th>\n",
       "      <th>row one</th>\n",
       "      <td>0.192222</td>\n",
       "      <td>0.763168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row two</th>\n",
       "      <td>0.015745</td>\n",
       "      <td>0.737682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row three</th>\n",
       "      <td>0.480935</td>\n",
       "      <td>0.412222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">AR</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0</th>\n",
       "      <th>row one</th>\n",
       "      <td>0.552720</td>\n",
       "      <td>0.502444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row two</th>\n",
       "      <td>0.178515</td>\n",
       "      <td>0.330177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row three</th>\n",
       "      <td>0.931378</td>\n",
       "      <td>0.815271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1</th>\n",
       "      <th>row one</th>\n",
       "      <td>0.163431</td>\n",
       "      <td>0.694237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row two</th>\n",
       "      <td>0.630829</td>\n",
       "      <td>0.493178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row three</th>\n",
       "      <td>0.033548</td>\n",
       "      <td>0.560382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">AS</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>row one</th>\n",
       "      <td>0.229722</td>\n",
       "      <td>0.844735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row two</th>\n",
       "      <td>0.756024</td>\n",
       "      <td>0.452571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              col A     col B\n",
       "STABBR RELAFFIL                              \n",
       "AK     0        row one    0.864879  0.085312\n",
       "                row two    0.539662  0.762609\n",
       "                row three  0.149195  0.214124\n",
       "       1        row one    0.838426  0.444579\n",
       "                row two    0.895184  0.217259\n",
       "                row three  0.323294  0.174294\n",
       "AL     0        row one    0.301533  0.710610\n",
       "                row two    0.980481  0.653199\n",
       "                row three  0.199440  0.465990\n",
       "       1        row one    0.192222  0.763168\n",
       "                row two    0.015745  0.737682\n",
       "                row three  0.480935  0.412222\n",
       "AR     0        row one    0.552720  0.502444\n",
       "                row two    0.178515  0.330177\n",
       "                row three  0.931378  0.815271\n",
       "       1        row one    0.163431  0.694237\n",
       "                row two    0.630829  0.493178\n",
       "                row three  0.033548  0.560382\n",
       "AS     0        row one    0.229722  0.844735\n",
       "                row two    0.756024  0.452571"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college.groupby(['STABBR', 'RELAFFIL']).apply(return_df).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But one caveat is that `apply` may not be the fastest way. For instance, suppose we want to calculate the average SAT Math scores per state weighted by undergraduate population. There are two ways of finishing this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First do some house cleaning\n",
    "college_drop = college[['STABBR', 'SATMTMID', 'UGDS']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.82 ms ± 39.5 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit # Not using apply - calculate the weighted sums before groupby\n",
    "college_drop['MATH_WT'] = college_drop['SATMTMID'] * college_drop['UGDS']\n",
    "c1 = college_drop.groupby('STABBR')['MATH_WT', 'UGDS'].agg('sum')\n",
    "(c1['MATH_WT'] / c1['UGDS']).astype(int).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_wa(df):\n",
    "    wa =  (df['SATMTMID'] * df['UGDS']).sum() / df['UGDS'].sum()\n",
    "    return wa.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.2 ms ± 4.35 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit college_drop.groupby('STABBR').apply(calc_wa).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- We used Python's iterator protocol to transform the raw data to a table\n",
    "- We saw how Dask could handle larger-than-memory data with a familiar API\n",
    "- We used groupby to analyze data by subsets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
